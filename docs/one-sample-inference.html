<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 7 One-Sample Inference | Statistics Using Technology</title>
  <meta name="description" content="An introductory statistics textbook." />
  <meta name="generator" content="bookdown 0.22 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 7 One-Sample Inference | Statistics Using Technology" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="An introductory statistics textbook." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 7 One-Sample Inference | Statistics Using Technology" />
  
  <meta name="twitter:description" content="An introductory statistics textbook." />
  

<meta name="author" content="Kathryn Kozak" />


<meta name="date" content="2021-08-11" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="continuous-probability-distributions.html"/>
<link rel="next" href="estimation.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>
<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Statistics Using Technology</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a><ul>
<li class="chapter" data-level="0.1" data-path="index.html"><a href="index.html#acknowledgments"><i class="fa fa-check"></i><b>0.1</b> Acknowledgments:</a></li>
<li class="chapter" data-level="0.2" data-path="index.html"><a href="index.html#new-to-the-third-edition"><i class="fa fa-check"></i><b>0.2</b> New to the Third Edition:</a></li>
<li class="chapter" data-level="0.3" data-path="index.html"><a href="index.html#packages-needed-for-rstudio"><i class="fa fa-check"></i><b>0.3</b> Packages needed for RStudio:</a></li>
<li class="chapter" data-level="0.4" data-path="index.html"><a href="index.html#creative-commons-license"><i class="fa fa-check"></i><b>0.4</b> Creative commons license:</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="statistical-basics.html"><a href="statistical-basics.html"><i class="fa fa-check"></i><b>1</b> Statistical Basics</a><ul>
<li class="chapter" data-level="1.1" data-path="statistical-basics.html"><a href="statistical-basics.html#what-is-statistics"><i class="fa fa-check"></i><b>1.1</b> What is Statistics?</a><ul>
<li class="chapter" data-level="1.1.1" data-path="statistical-basics.html"><a href="statistical-basics.html#example-stating-definitions-for-qualitative-variable"><i class="fa fa-check"></i><b>1.1.1</b> Example: Stating Definitions for Qualitative Variable**</a></li>
<li class="chapter" data-level="1.1.2" data-path="statistical-basics.html"><a href="statistical-basics.html#example-stating-definitions-for-qualitative-variable-1"><i class="fa fa-check"></i><b>1.1.2</b> Example: Stating Definitions for Qualitative Variable</a></li>
<li class="chapter" data-level="1.1.3" data-path="statistical-basics.html"><a href="statistical-basics.html#example-stating-definitions-for-quantitative-variable"><i class="fa fa-check"></i><b>1.1.3</b> Example: Stating Definitions for Quantitative Variable</a></li>
<li class="chapter" data-level="1.1.4" data-path="statistical-basics.html"><a href="statistical-basics.html#example-stating-definitions-for-quantitative-variable-1"><i class="fa fa-check"></i><b>1.1.4</b> Example: Stating Definitions for Quantitative Variable</a></li>
<li class="chapter" data-level="1.1.5" data-path="statistical-basics.html"><a href="statistical-basics.html#example-discrete-or-continuous"><i class="fa fa-check"></i><b>1.1.5</b> Example: Discrete or Continuous</a></li>
<li class="chapter" data-level="1.1.6" data-path="statistical-basics.html"><a href="statistical-basics.html#example-measurement-scale"><i class="fa fa-check"></i><b>1.1.6</b> Example: Measurement Scale</a></li>
<li class="chapter" data-level="1.1.7" data-path="statistical-basics.html"><a href="statistical-basics.html#homework-section-1.1"><i class="fa fa-check"></i><b>1.1.7</b> Homework Section 1.1</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="statistical-basics.html"><a href="statistical-basics.html#sampling-methods"><i class="fa fa-check"></i><b>1.2</b> Sampling Methods</a><ul>
<li class="chapter" data-level="1.2.1" data-path="statistical-basics.html"><a href="statistical-basics.html#example-choosing-a-simple-random-sample"><i class="fa fa-check"></i><b>1.2.1</b> Example: Choosing a Simple Random Sample</a></li>
<li class="chapter" data-level="1.2.2" data-path="statistical-basics.html"><a href="statistical-basics.html#example-how-not-to-choose-a-simple-random-sample"><i class="fa fa-check"></i><b>1.2.2</b> Example: How Not to Choose a Simple Random Sample</a></li>
<li class="chapter" data-level="1.2.3" data-path="statistical-basics.html"><a href="statistical-basics.html#example-how-to-choose-a-simple-random-sample-using-r"><i class="fa fa-check"></i><b>1.2.3</b> Example: How to Choose a Simple Random Sample using R</a></li>
<li class="chapter" data-level="1.2.4" data-path="statistical-basics.html"><a href="statistical-basics.html#example-sampling-type"><i class="fa fa-check"></i><b>1.2.4</b> Example: Sampling type</a></li>
<li class="chapter" data-level="1.2.5" data-path="statistical-basics.html"><a href="statistical-basics.html#homework-section-1.2"><i class="fa fa-check"></i><b>1.2.5</b> Homework Section 1.2</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="statistical-basics.html"><a href="statistical-basics.html#experimental-design"><i class="fa fa-check"></i><b>1.3</b> Experimental Design</a><ul>
<li class="chapter" data-level="1.3.1" data-path="statistical-basics.html"><a href="statistical-basics.html#example-observational-study-or-experiment"><i class="fa fa-check"></i><b>1.3.1</b> Example: Observational Study or Experiment</a></li>
<li class="chapter" data-level="1.3.2" data-path="statistical-basics.html"><a href="statistical-basics.html#homework-section-1.3"><i class="fa fa-check"></i><b>1.3.2</b> Homework Section 1.3</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="statistical-basics.html"><a href="statistical-basics.html#how-not-to-do-statistics"><i class="fa fa-check"></i><b>1.4</b> How Not to Do Statistics</a><ul>
<li class="chapter" data-level="1.4.1" data-path="statistical-basics.html"><a href="statistical-basics.html#example-bias-in-a-study"><i class="fa fa-check"></i><b>1.4.1</b> Example: Bias in a Study**</a></li>
<li class="chapter" data-level="1.4.2" data-path="statistical-basics.html"><a href="statistical-basics.html#example-cause-and-effect"><i class="fa fa-check"></i><b>1.4.2</b> Example: Cause and Effect</a></li>
<li class="chapter" data-level="1.4.3" data-path="statistical-basics.html"><a href="statistical-basics.html#example-generalizations"><i class="fa fa-check"></i><b>1.4.3</b> Example: Generalizations</a></li>
<li class="chapter" data-level="1.4.4" data-path="statistical-basics.html"><a href="statistical-basics.html#homework-section-1.4"><i class="fa fa-check"></i><b>1.4.4</b> Homework Section 1.4</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="graphical-descriptions-of-data.html"><a href="graphical-descriptions-of-data.html"><i class="fa fa-check"></i><b>2</b> Graphical Descriptions of Data</a><ul>
<li class="chapter" data-level="2.1" data-path="graphical-descriptions-of-data.html"><a href="graphical-descriptions-of-data.html#qualitative-data"><i class="fa fa-check"></i><b>2.1</b> Qualitative Data</a><ul>
<li class="chapter" data-level="2.1.1" data-path="graphical-descriptions-of-data.html"><a href="graphical-descriptions-of-data.html#example-drawing-a-bar-chart"><i class="fa fa-check"></i><b>2.1.1</b> Example: Drawing a Bar Chart**</a></li>
<li class="chapter" data-level="2.1.2" data-path="graphical-descriptions-of-data.html"><a href="graphical-descriptions-of-data.html#homework"><i class="fa fa-check"></i><b>2.1.2</b> Homework</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="graphical-descriptions-of-data.html"><a href="graphical-descriptions-of-data.html#quantitative-data"><i class="fa fa-check"></i><b>2.2</b> Quantitative Data</a><ul>
<li class="chapter" data-level="2.2.1" data-path="graphical-descriptions-of-data.html"><a href="graphical-descriptions-of-data.html#example-drawing-a-histogram-and-density-plot"><i class="fa fa-check"></i><b>2.2.1</b> Example: Drawing a Histogram and Density plot</a></li>
<li class="chapter" data-level="2.2.2" data-path="graphical-descriptions-of-data.html"><a href="graphical-descriptions-of-data.html#example-drawing-a-histogram-and-density-plot-1"><i class="fa fa-check"></i><b>2.2.2</b> Example: Drawing a Histogram and Density plot</a></li>
<li class="chapter" data-level="2.2.3" data-path="graphical-descriptions-of-data.html"><a href="graphical-descriptions-of-data.html#homework-1"><i class="fa fa-check"></i><b>2.2.3</b> Homework</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="graphical-descriptions-of-data.html"><a href="graphical-descriptions-of-data.html#other-graphical-representations-of-data"><i class="fa fa-check"></i><b>2.3</b> Other Graphical Representations of Data</a><ul>
<li class="chapter" data-level="2.3.1" data-path="graphical-descriptions-of-data.html"><a href="graphical-descriptions-of-data.html#example-scatter-plot"><i class="fa fa-check"></i><b>2.3.1</b> Example: <strong>Scatter Plot</strong></a></li>
<li class="chapter" data-level="2.3.2" data-path="graphical-descriptions-of-data.html"><a href="graphical-descriptions-of-data.html#example-time-series-plot"><i class="fa fa-check"></i><b>2.3.2</b> Example: Time-Series Plot**</a></li>
<li class="chapter" data-level="2.3.3" data-path="graphical-descriptions-of-data.html"><a href="graphical-descriptions-of-data.html#homework-2"><i class="fa fa-check"></i><b>2.3.3</b> Homework</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="numerical-descriptions-of-data.html"><a href="numerical-descriptions-of-data.html"><i class="fa fa-check"></i><b>3</b> Numerical Descriptions of Data</a><ul>
<li class="chapter" data-level="3.1" data-path="numerical-descriptions-of-data.html"><a href="numerical-descriptions-of-data.html#measures-of-center"><i class="fa fa-check"></i><b>3.1</b> Measures of Center</a><ul>
<li class="chapter" data-level="3.1.1" data-path="numerical-descriptions-of-data.html"><a href="numerical-descriptions-of-data.html#example-finding-the-mean-and-median-using-r"><i class="fa fa-check"></i><b>3.1.1</b> Example: Finding the Mean and Median using R</a></li>
<li class="chapter" data-level="3.1.2" data-path="numerical-descriptions-of-data.html"><a href="numerical-descriptions-of-data.html#example-finding-mean-and-median-with-filtering"><i class="fa fa-check"></i><b>3.1.2</b> Example: Finding Mean and Median with filtering</a></li>
<li class="chapter" data-level="3.1.3" data-path="numerical-descriptions-of-data.html"><a href="numerical-descriptions-of-data.html#example-affect-of-extreme-values-on-mean-and-median"><i class="fa fa-check"></i><b>3.1.3</b> Example: Affect of Extreme Values on Mean and Median**</a></li>
<li class="chapter" data-level="3.1.4" data-path="numerical-descriptions-of-data.html"><a href="numerical-descriptions-of-data.html#example-weighted-average"><i class="fa fa-check"></i><b>3.1.4</b> Example: Weighted Average</a></li>
<li class="chapter" data-level="3.1.5" data-path="numerical-descriptions-of-data.html"><a href="numerical-descriptions-of-data.html#example-weighted-average-1"><i class="fa fa-check"></i><b>3.1.5</b> Example: Weighted Average</a></li>
<li class="chapter" data-level="3.1.6" data-path="numerical-descriptions-of-data.html"><a href="numerical-descriptions-of-data.html#homework-3"><i class="fa fa-check"></i><b>3.1.6</b> Homework</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="numerical-descriptions-of-data.html"><a href="numerical-descriptions-of-data.html#measures-of-spread"><i class="fa fa-check"></i><b>3.2</b> Measures of Spread</a><ul>
<li class="chapter" data-level="3.2.1" data-path="numerical-descriptions-of-data.html"><a href="numerical-descriptions-of-data.html#example-range"><i class="fa fa-check"></i><b>3.2.1</b> Example: Range</a></li>
<li class="chapter" data-level="3.2.2" data-path="numerical-descriptions-of-data.html"><a href="numerical-descriptions-of-data.html#example-finding-the-standard-deviation"><i class="fa fa-check"></i><b>3.2.2</b> Example: Finding the Standard Deviation</a></li>
<li class="chapter" data-level="3.2.3" data-path="numerical-descriptions-of-data.html"><a href="numerical-descriptions-of-data.html#example-the-gneral-rule"><i class="fa fa-check"></i><b>3.2.3</b> Example: the gneral rule</a></li>
<li class="chapter" data-level="3.2.4" data-path="numerical-descriptions-of-data.html"><a href="numerical-descriptions-of-data.html#example-determining-if-a-value-is-unusual"><i class="fa fa-check"></i><b>3.2.4</b> Example: Determining If a Value Is Unusual</a></li>
<li class="chapter" data-level="3.2.5" data-path="numerical-descriptions-of-data.html"><a href="numerical-descriptions-of-data.html#homework-4"><i class="fa fa-check"></i><b>3.2.5</b> Homework</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="numerical-descriptions-of-data.html"><a href="numerical-descriptions-of-data.html#ranking"><i class="fa fa-check"></i><b>3.3</b> Ranking</a><ul>
<li class="chapter" data-level="3.3.1" data-path="numerical-descriptions-of-data.html"><a href="numerical-descriptions-of-data.html#example-interpreting-percentile"><i class="fa fa-check"></i><b>3.3.1</b> Example: Interpreting Percentile</a></li>
<li class="chapter" data-level="3.3.2" data-path="numerical-descriptions-of-data.html"><a href="numerical-descriptions-of-data.html#example-percentile-versus-score"><i class="fa fa-check"></i><b>3.3.2</b> Example: Percentile Versus Score</a></li>
<li class="chapter" data-level="3.3.3" data-path="numerical-descriptions-of-data.html"><a href="numerical-descriptions-of-data.html#example-five-number-summary-and-boxplot"><i class="fa fa-check"></i><b>3.3.3</b> Example: Five-number Summary and Boxplot</a></li>
<li class="chapter" data-level="3.3.4" data-path="numerical-descriptions-of-data.html"><a href="numerical-descriptions-of-data.html#example-separating-based-on-a-factor"><i class="fa fa-check"></i><b>3.3.4</b> Example: Separating based on a factor</a></li>
<li class="chapter" data-level="3.3.5" data-path="numerical-descriptions-of-data.html"><a href="numerical-descriptions-of-data.html#example-putting-it-all-together"><i class="fa fa-check"></i><b>3.3.5</b> Example: Putting it all together</a></li>
<li class="chapter" data-level="3.3.6" data-path="numerical-descriptions-of-data.html"><a href="numerical-descriptions-of-data.html#homework-5"><i class="fa fa-check"></i><b>3.3.6</b> Homework</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="probability.html"><a href="probability.html"><i class="fa fa-check"></i><b>4</b> Probability</a><ul>
<li class="chapter" data-level="4.1" data-path="probability.html"><a href="probability.html#empirical-probability"><i class="fa fa-check"></i><b>4.1</b> Empirical Probability</a><ul>
<li class="chapter" data-level="4.1.1" data-path="probability.html"><a href="probability.html#example-statistics-class-survey"><i class="fa fa-check"></i><b>4.1.1</b> Example: Statistics class survey</a></li>
<li class="chapter" data-level="4.1.2" data-path="probability.html"><a href="probability.html#homework-6"><i class="fa fa-check"></i><b>4.1.2</b> Homework</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="probability.html"><a href="probability.html#theoretical-probability"><i class="fa fa-check"></i><b>4.2</b> Theoretical Probability</a><ul>
<li class="chapter" data-level="4.2.1" data-path="probability.html"><a href="probability.html#example-equally-likely-outcomes"><i class="fa fa-check"></i><b>4.2.1</b> Example: Equally Likely Outcomes</a></li>
<li class="chapter" data-level="4.2.2" data-path="probability.html"><a href="probability.html#example-calculating-theoretical-probabilities"><i class="fa fa-check"></i><b>4.2.2</b> Example: Calculating Theoretical Probabilities</a></li>
<li class="chapter" data-level="4.2.3" data-path="probability.html"><a href="probability.html#example-calculating-theoretical-probabilities-1"><i class="fa fa-check"></i><b>4.2.3</b> Example: Calculating Theoretical Probabilities</a></li>
<li class="chapter" data-level="4.2.4" data-path="probability.html"><a href="probability.html#example-calculating-theoretical-probabilities-2"><i class="fa fa-check"></i><b>4.2.4</b> Example: Calculating Theoretical Probabilities</a></li>
<li class="chapter" data-level="4.2.5" data-path="probability.html"><a href="probability.html#example-complementary-events"><i class="fa fa-check"></i><b>4.2.5</b> Example: Complementary Events</a></li>
<li class="chapter" data-level="4.2.6" data-path="probability.html"><a href="probability.html#example-using-the-complement-to-find-probabilities"><i class="fa fa-check"></i><b>4.2.6</b> Example: Using the Complement to Find Probabilities</a></li>
<li class="chapter" data-level="4.2.7" data-path="probability.html"><a href="probability.html#example-using-addition-rules"><i class="fa fa-check"></i><b>4.2.7</b> Example: Using Addition Rules</a></li>
<li class="chapter" data-level="4.2.8" data-path="probability.html"><a href="probability.html#example-odds-against-and-payoff-odds"><i class="fa fa-check"></i><b>4.2.8</b> Example: Odds Against and Payoff Odds</a></li>
<li class="chapter" data-level="4.2.9" data-path="probability.html"><a href="probability.html#homework-7"><i class="fa fa-check"></i><b>4.2.9</b> Homework</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="probability.html"><a href="probability.html#conditional-probability"><i class="fa fa-check"></i><b>4.3</b> Conditional Probability</a><ul>
<li class="chapter" data-level="4.3.1" data-path="probability.html"><a href="probability.html#example-conditional-probabilities"><i class="fa fa-check"></i><b>4.3.1</b> Example: Conditional Probabilities</a></li>
<li class="chapter" data-level="4.3.2" data-path="probability.html"><a href="probability.html#example-independent-events"><i class="fa fa-check"></i><b>4.3.2</b> Example: Independent Events</a></li>
<li class="chapter" data-level="4.3.3" data-path="probability.html"><a href="probability.html#example-multiplication-rule"><i class="fa fa-check"></i><b>4.3.3</b> Example: Multiplication Rule</a></li>
<li class="chapter" data-level="4.3.4" data-path="probability.html"><a href="probability.html#example-application-problem"><i class="fa fa-check"></i><b>4.3.4</b> Example: Application Problem</a></li>
<li class="chapter" data-level="4.3.5" data-path="probability.html"><a href="probability.html#homework-8"><i class="fa fa-check"></i><b>4.3.5</b> Homework</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="probability.html"><a href="probability.html#counting-techniques"><i class="fa fa-check"></i><b>4.4</b> Counting Techniques</a><ul>
<li class="chapter" data-level="4.4.1" data-path="probability.html"><a href="probability.html#example-multiplication-rule-in-counting"><i class="fa fa-check"></i><b>4.4.1</b> Example: Multiplication Rule in Counting</a></li>
<li class="chapter" data-level="4.4.2" data-path="probability.html"><a href="probability.html#example-multiplication-rule-in-counting-1"><i class="fa fa-check"></i><b>4.4.2</b> Example: Multiplication Rule in Counting</a></li>
<li class="chapter" data-level="4.4.3" data-path="probability.html"><a href="probability.html#homework-9"><i class="fa fa-check"></i><b>4.4.3</b> Homework</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="discrete-probability-distributions.html"><a href="discrete-probability-distributions.html"><i class="fa fa-check"></i><b>5</b> Discrete Probability Distributions</a><ul>
<li class="chapter" data-level="5.1" data-path="discrete-probability-distributions.html"><a href="discrete-probability-distributions.html#basics-of-probability-distributions"><i class="fa fa-check"></i><b>5.1</b> Basics of Probability Distributions</a><ul>
<li class="chapter" data-level="5.1.1" data-path="discrete-probability-distributions.html"><a href="discrete-probability-distributions.html#example-probability-distribution"><i class="fa fa-check"></i><b>5.1.1</b> Example: Probability Distribution</a></li>
<li class="chapter" data-level="5.1.2" data-path="discrete-probability-distributions.html"><a href="discrete-probability-distributions.html#example-calculating-the-expected-value"><i class="fa fa-check"></i><b>5.1.2</b> Example: Calculating the Expected Value</a></li>
<li class="chapter" data-level="5.1.3" data-path="discrete-probability-distributions.html"><a href="discrete-probability-distributions.html#example-is-the-event-unusual"><i class="fa fa-check"></i><b>5.1.3</b> Example: Is the Event Unusual</a></li>
<li class="chapter" data-level="5.1.4" data-path="discrete-probability-distributions.html"><a href="discrete-probability-distributions.html#homework-10"><i class="fa fa-check"></i><b>5.1.4</b> Homework</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="discrete-probability-distributions.html"><a href="discrete-probability-distributions.html#binomial-probability-distribution"><i class="fa fa-check"></i><b>5.2</b> Binomial Probability Distribution</a><ul>
<li class="chapter" data-level="5.2.1" data-path="discrete-probability-distributions.html"><a href="discrete-probability-distributions.html#example-calculating-binomial-probabilities"><i class="fa fa-check"></i><b>5.2.1</b> Example: Calculating Binomial Probabilities</a></li>
<li class="chapter" data-level="5.2.2" data-path="discrete-probability-distributions.html"><a href="discrete-probability-distributions.html#example-calculating-binomial-probabilities-1"><i class="fa fa-check"></i><b>5.2.2</b> Example: Calculating Binomial Probabilities</a></li>
<li class="chapter" data-level="5.2.3" data-path="discrete-probability-distributions.html"><a href="discrete-probability-distributions.html#homework-11"><i class="fa fa-check"></i><b>5.2.3</b> Homework</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="discrete-probability-distributions.html"><a href="discrete-probability-distributions.html#mean-and-standard-deviation-of-binomial-distribution"><i class="fa fa-check"></i><b>5.3</b> Mean and Standard Deviation of Binomial Distribution</a><ul>
<li class="chapter" data-level="5.3.1" data-path="discrete-probability-distributions.html"><a href="discrete-probability-distributions.html#example-finding-the-probability-distribution-mean-variance-and-standard-deviation-of-a-binomial-distribution"><i class="fa fa-check"></i><b>5.3.1</b> Example: Finding the Probability Distribution, Mean, Variance and Standard Deviation of a Binomial Distribution</a></li>
<li class="chapter" data-level="5.3.2" data-path="discrete-probability-distributions.html"><a href="discrete-probability-distributions.html#homework-12"><i class="fa fa-check"></i><b>5.3.2</b> Homework</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="continuous-probability-distributions.html"><a href="continuous-probability-distributions.html"><i class="fa fa-check"></i><b>6</b> Continuous Probability Distributions</a><ul>
<li class="chapter" data-level="6.1" data-path="continuous-probability-distributions.html"><a href="continuous-probability-distributions.html#finding-probabilities-for-the-normal-distribution"><i class="fa fa-check"></i><b>6.1</b> Finding Probabilities for the Normal Distribution</a><ul>
<li class="chapter" data-level="6.1.1" data-path="continuous-probability-distributions.html"><a href="continuous-probability-distributions.html#example-general-normal-distribution"><i class="fa fa-check"></i><b>6.1.1</b> Example: General Normal Distribution</a></li>
<li class="chapter" data-level="6.1.2" data-path="continuous-probability-distributions.html"><a href="continuous-probability-distributions.html#example-general-normal-distribution-1"><i class="fa fa-check"></i><b>6.1.2</b> Example: General Normal Distribution</a></li>
<li class="chapter" data-level="6.1.3" data-path="continuous-probability-distributions.html"><a href="continuous-probability-distributions.html#homework-13"><i class="fa fa-check"></i><b>6.1.3</b> Homework</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="continuous-probability-distributions.html"><a href="continuous-probability-distributions.html#assessing-normality"><i class="fa fa-check"></i><b>6.2</b> Assessing Normality</a><ul>
<li class="chapter" data-level="6.2.1" data-path="continuous-probability-distributions.html"><a href="continuous-probability-distributions.html#example-is-it-normal"><i class="fa fa-check"></i><b>6.2.1</b> Example: Is It Normal?</a></li>
<li class="chapter" data-level="6.2.2" data-path="continuous-probability-distributions.html"><a href="continuous-probability-distributions.html#example-is-it-normal-1"><i class="fa fa-check"></i><b>6.2.2</b> Example: Is It Normal?</a></li>
<li class="chapter" data-level="6.2.3" data-path="continuous-probability-distributions.html"><a href="continuous-probability-distributions.html#homework-14"><i class="fa fa-check"></i><b>6.2.3</b> Homework</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="continuous-probability-distributions.html"><a href="continuous-probability-distributions.html#sampling-distribution-and-the-central-limit-theorem"><i class="fa fa-check"></i><b>6.3</b> Sampling Distribution and the Central Limit Theorem</a><ul>
<li class="chapter" data-level="6.3.1" data-path="continuous-probability-distributions.html"><a href="continuous-probability-distributions.html#example-sampling-distribution"><i class="fa fa-check"></i><b>6.3.1</b> Example: Sampling Distribution</a></li>
<li class="chapter" data-level="6.3.2" data-path="continuous-probability-distributions.html"><a href="continuous-probability-distributions.html#example-finding-probabilities-for-sample-means"><i class="fa fa-check"></i><b>6.3.2</b> Example: Finding Probabilities for Sample Means</a></li>
<li class="chapter" data-level="6.3.3" data-path="continuous-probability-distributions.html"><a href="continuous-probability-distributions.html#example-finding-probabilities-for-sample-means-1"><i class="fa fa-check"></i><b>6.3.3</b> Example: Finding Probabilities for Sample Means</a></li>
<li class="chapter" data-level="6.3.4" data-path="continuous-probability-distributions.html"><a href="continuous-probability-distributions.html#homework-15"><i class="fa fa-check"></i><b>6.3.4</b> Homework</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="one-sample-inference.html"><a href="one-sample-inference.html"><i class="fa fa-check"></i><b>7</b> One-Sample Inference</a><ul>
<li class="chapter" data-level="7.1" data-path="one-sample-inference.html"><a href="one-sample-inference.html#basics-of-hypothesis-testing"><i class="fa fa-check"></i><b>7.1</b> Basics of Hypothesis Testing</a><ul>
<li class="chapter" data-level="7.1.1" data-path="one-sample-inference.html"><a href="one-sample-inference.html#example-basics-of-hypothesis-testing"><i class="fa fa-check"></i><b>7.1.1</b> Example: Basics of Hypothesis Testing</a></li>
<li class="chapter" data-level="7.1.2" data-path="one-sample-inference.html"><a href="one-sample-inference.html#example-battery-example-revisited."><i class="fa fa-check"></i><b>7.1.2</b> Example: Battery Example Revisited.</a></li>
<li class="chapter" data-level="7.1.3" data-path="one-sample-inference.html"><a href="one-sample-inference.html#example-conclusions-in-hypothesis-tests"><i class="fa fa-check"></i><b>7.1.3</b> Example: Conclusions in Hypothesis Tests</a></li>
<li class="chapter" data-level="7.1.4" data-path="one-sample-inference.html"><a href="one-sample-inference.html#example-stating-hypotheses"><i class="fa fa-check"></i><b>7.1.4</b> Example: Stating Hypotheses</a></li>
<li class="chapter" data-level="7.1.5" data-path="one-sample-inference.html"><a href="one-sample-inference.html#example-stating-type-i-and-ii-errors-and-picking-level-of-significance"><i class="fa fa-check"></i><b>7.1.5</b> Example: Stating Type I and II Errors and Picking Level of Significance</a></li>
<li class="chapter" data-level="7.1.6" data-path="one-sample-inference.html"><a href="one-sample-inference.html#homework-16"><i class="fa fa-check"></i><b>7.1.6</b> Homework</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="one-sample-inference.html"><a href="one-sample-inference.html#one-sample-proportion-test"><i class="fa fa-check"></i><b>7.2</b> One-Sample Proportion Test</a><ul>
<li class="chapter" data-level="7.2.1" data-path="one-sample-inference.html"><a href="one-sample-inference.html#example-hypothesis-test-for-one-proportion"><i class="fa fa-check"></i><b>7.2.1</b> Example: Hypothesis Test for One Proportion</a></li>
<li class="chapter" data-level="7.2.2" data-path="one-sample-inference.html"><a href="one-sample-inference.html#example-hypothesis-test-for-one-proportion-1"><i class="fa fa-check"></i><b>7.2.2</b> Example: Hypothesis Test for One Proportion</a></li>
<li class="chapter" data-level="7.2.3" data-path="one-sample-inference.html"><a href="one-sample-inference.html#homework-17"><i class="fa fa-check"></i><b>7.2.3</b> Homework</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="one-sample-inference.html"><a href="one-sample-inference.html#one-sample-test-for-the-mean"><i class="fa fa-check"></i><b>7.3</b> One-Sample Test for the Mean</a><ul>
<li class="chapter" data-level="7.3.1" data-path="one-sample-inference.html"><a href="one-sample-inference.html#example-resampling"><i class="fa fa-check"></i><b>7.3.1</b> Example: Resampling</a></li>
<li class="chapter" data-level="7.3.2" data-path="one-sample-inference.html"><a href="one-sample-inference.html#example-test-of-the-mean-using-one-sample-t-test"><i class="fa fa-check"></i><b>7.3.2</b> Example: Test of the Mean Using One Sample T-test</a></li>
<li class="chapter" data-level="7.3.3" data-path="one-sample-inference.html"><a href="one-sample-inference.html#example-test-of-the-mean-using-one-sample-t-test-1"><i class="fa fa-check"></i><b>7.3.3</b> Example: Test of the Mean Using One Sample T-test</a></li>
<li class="chapter" data-level="7.3.4" data-path="one-sample-inference.html"><a href="one-sample-inference.html#homework-18"><i class="fa fa-check"></i><b>7.3.4</b> Homework</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="estimation.html"><a href="estimation.html"><i class="fa fa-check"></i><b>8</b> Estimation</a><ul>
<li class="chapter" data-level="8.1" data-path="estimation.html"><a href="estimation.html#basics-of-confidence-intervals"><i class="fa fa-check"></i><b>8.1</b> Basics of Confidence Intervals</a><ul>
<li class="chapter" data-level="8.1.1" data-path="estimation.html"><a href="estimation.html#example-stating-the-statistical-and-real-world-interpretations-for-a-confidence-interval"><i class="fa fa-check"></i><b>8.1.1</b> Example: Stating the Statistical and Real World Interpretations for a Confidence Interval</a></li>
<li class="chapter" data-level="8.1.2" data-path="estimation.html"><a href="estimation.html#homework-19"><i class="fa fa-check"></i><b>8.1.2</b> Homework</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="estimation.html"><a href="estimation.html#one-sample-interval-for-the-proportion"><i class="fa fa-check"></i><b>8.2</b> One-Sample Interval for the Proportion</a><ul>
<li class="chapter" data-level="8.2.1" data-path="estimation.html"><a href="estimation.html#example-confidence-interval-for-the-population-proportion"><i class="fa fa-check"></i><b>8.2.1</b> Example: Confidence Interval for the Population Proportion</a></li>
<li class="chapter" data-level="8.2.2" data-path="estimation.html"><a href="estimation.html#example-confidence-interval-for-the-population-proportion-1"><i class="fa fa-check"></i><b>8.2.2</b> Example: Confidence Interval for the Population Proportion</a></li>
<li class="chapter" data-level="8.2.3" data-path="estimation.html"><a href="estimation.html#homework-20"><i class="fa fa-check"></i><b>8.2.3</b> Homework</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="estimation.html"><a href="estimation.html#one-sample-interval-for-the-mean"><i class="fa fa-check"></i><b>8.3</b> One-Sample Interval for the Mean</a><ul>
<li class="chapter" data-level="8.3.1" data-path="estimation.html"><a href="estimation.html#example-confidence-interval-for-the-population-mean"><i class="fa fa-check"></i><b>8.3.1</b> Example: Confidence Interval for the Population Mean</a></li>
<li class="chapter" data-level="8.3.2" data-path="estimation.html"><a href="estimation.html#example-confidence-interval-for-the-population-mean-1"><i class="fa fa-check"></i><b>8.3.2</b> Example: Confidence Interval for the Population Mean</a></li>
<li class="chapter" data-level="8.3.3" data-path="estimation.html"><a href="estimation.html#homework-21"><i class="fa fa-check"></i><b>8.3.3</b> Homework</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="two-sample-inference.html"><a href="two-sample-inference.html"><i class="fa fa-check"></i><b>9</b> Two-Sample Inference</a><ul>
<li class="chapter" data-level="9.1" data-path="two-sample-inference.html"><a href="two-sample-inference.html#two-proportions"><i class="fa fa-check"></i><b>9.1</b> Two Proportions</a><ul>
<li class="chapter" data-level="9.1.1" data-path="two-sample-inference.html"><a href="two-sample-inference.html#example-hypothesis-test-for-two-population-proportions"><i class="fa fa-check"></i><b>9.1.1</b> Example: Hypothesis Test for Two Population Proportions</a></li>
<li class="chapter" data-level="9.1.2" data-path="two-sample-inference.html"><a href="two-sample-inference.html#example-confidence-interval-for-two-population-proportions"><i class="fa fa-check"></i><b>9.1.2</b> Example: Confidence Interval for Two Population Proportions</a></li>
<li class="chapter" data-level="9.1.3" data-path="two-sample-inference.html"><a href="two-sample-inference.html#homework-22"><i class="fa fa-check"></i><b>9.1.3</b> Homework</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="two-sample-inference.html"><a href="two-sample-inference.html#paired-samples-for-two-means"><i class="fa fa-check"></i><b>9.2</b> Paired Samples for Two Means</a><ul>
<li class="chapter" data-level="9.2.1" data-path="two-sample-inference.html"><a href="two-sample-inference.html#example-independent-or-dependent-samples"><i class="fa fa-check"></i><b>9.2.1</b> Example: Independent or Dependent Samples</a></li>
<li class="chapter" data-level="9.2.2" data-path="two-sample-inference.html"><a href="two-sample-inference.html#example-hypothesis-test-for-paired-samples"><i class="fa fa-check"></i><b>9.2.2</b> Example: Hypothesis Test for Paired Samples</a></li>
<li class="chapter" data-level="9.2.3" data-path="two-sample-inference.html"><a href="two-sample-inference.html#example-hypothesis-test-for-paired-samples-1"><i class="fa fa-check"></i><b>9.2.3</b> Example: Hypothesis Test for Paired Samples</a></li>
<li class="chapter" data-level="9.2.4" data-path="two-sample-inference.html"><a href="two-sample-inference.html#example-confidence-interval-for-paired-samples"><i class="fa fa-check"></i><b>9.2.4</b> Example: Confidence Interval for Paired Samples</a></li>
<li class="chapter" data-level="9.2.5" data-path="two-sample-inference.html"><a href="two-sample-inference.html#homework-23"><i class="fa fa-check"></i><b>9.2.5</b> Homework</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="two-sample-inference.html"><a href="two-sample-inference.html#independent-samples-for-two-means"><i class="fa fa-check"></i><b>9.3</b> Independent Samples for Two Means</a><ul>
<li class="chapter" data-level="9.3.1" data-path="two-sample-inference.html"><a href="two-sample-inference.html#example-hypothesis-test-for-two-means"><i class="fa fa-check"></i><b>9.3.1</b> Example: Hypothesis Test for Two Means</a></li>
<li class="chapter" data-level="9.3.2" data-path="two-sample-inference.html"><a href="two-sample-inference.html#example-confidence-interval-in-two-samples"><i class="fa fa-check"></i><b>9.3.2</b> Example: Confidence Interval in Two Samples</a></li>
<li class="chapter" data-level="9.3.3" data-path="two-sample-inference.html"><a href="two-sample-inference.html#example-hypothesis-test-for-two-means-1"><i class="fa fa-check"></i><b>9.3.3</b> Example: Hypothesis Test for Two Means</a></li>
<li class="chapter" data-level="9.3.4" data-path="two-sample-inference.html"><a href="two-sample-inference.html#example-confidence-interval-for-two-independent-samples"><i class="fa fa-check"></i><b>9.3.4</b> Example: Confidence Interval for Two Independent Samples</a></li>
<li class="chapter" data-level="9.3.5" data-path="two-sample-inference.html"><a href="two-sample-inference.html#homework-24"><i class="fa fa-check"></i><b>9.3.5</b> Homework</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="two-sample-inference.html"><a href="two-sample-inference.html#which-analysis-should-you-conduct"><i class="fa fa-check"></i><b>9.4</b> Which Analysis Should You Conduct?</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html"><i class="fa fa-check"></i><b>10</b> Regression and Correlation</a><ul>
<li class="chapter" data-level="10.1" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html#regression"><i class="fa fa-check"></i><b>10.1</b> Regression</a><ul>
<li class="chapter" data-level="10.1.1" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html#example-determining-if-there-is-a-relationship"><i class="fa fa-check"></i><b>10.1.1</b> Example: Determining If There Is a Relationship</a></li>
<li class="chapter" data-level="10.1.2" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html#homework-25"><i class="fa fa-check"></i><b>10.1.2</b> Homework</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html#correlation"><i class="fa fa-check"></i><b>10.2</b> Correlation</a><ul>
<li class="chapter" data-level="10.2.1" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html#example-find-the-coefficient-of-determinatin-r2"><i class="fa fa-check"></i><b>10.2.1</b> Example: Find the coefficient of determinatin <span class="math inline">\(R^2\)</span></a></li>
<li class="chapter" data-level="10.2.2" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html#example-calculating-the-linear-correlation-coefficient-r"><i class="fa fa-check"></i><b>10.2.2</b> Example: Calculating the Linear Correlation Coefficient, <em>r</em></a></li>
<li class="chapter" data-level="10.2.3" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html#example-correlation-versus-causation"><i class="fa fa-check"></i><b>10.2.3</b> Example: Correlation Versus Causation</a></li>
<li class="chapter" data-level="10.2.4" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html#homework-26"><i class="fa fa-check"></i><b>10.2.4</b> Homework</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html#inference-for-regression-and-correlation"><i class="fa fa-check"></i><b>10.3</b> Inference for Regression and Correlation</a><ul>
<li class="chapter" data-level="10.3.1" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html#example-finding-the-standard-error-of-the-estimate"><i class="fa fa-check"></i><b>10.3.1</b> Example: Finding the Standard Error of the Estimate</a></li>
<li class="chapter" data-level="10.3.2" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html#example-testing-the-claim-of-a-linear-correlation"><i class="fa fa-check"></i><b>10.3.2</b> Example: Testing the Claim of a Linear Correlation</a></li>
<li class="chapter" data-level="10.3.3" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html#homework-27"><i class="fa fa-check"></i><b>10.3.3</b> Homework</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="chi-square-and-anova-tests.html"><a href="chi-square-and-anova-tests.html"><i class="fa fa-check"></i><b>11</b> Chi-Square and ANOVA Tests</a><ul>
<li class="chapter" data-level="11.1" data-path="chi-square-and-anova-tests.html"><a href="chi-square-and-anova-tests.html#chi-square-test-for-independence"><i class="fa fa-check"></i><b>11.1</b> Chi-Square Test for Independence</a><ul>
<li class="chapter" data-level="11.1.1" data-path="chi-square-and-anova-tests.html"><a href="chi-square-and-anova-tests.html#example-hypothesis-test-with-chi-square-test"><i class="fa fa-check"></i><b>11.1.1</b> Example: Hypothesis Test with Chi-Square Test</a></li>
<li class="chapter" data-level="11.1.2" data-path="chi-square-and-anova-tests.html"><a href="chi-square-and-anova-tests.html#homework-28"><i class="fa fa-check"></i><b>11.1.2</b> Homework</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="chi-square-and-anova-tests.html"><a href="chi-square-and-anova-tests.html#chi-square-goodness-of-fit"><i class="fa fa-check"></i><b>11.2</b> Chi-Square Goodness of Fit</a><ul>
<li class="chapter" data-level="11.2.1" data-path="chi-square-and-anova-tests.html"><a href="chi-square-and-anova-tests.html#example-goodness-of-fit-test"><i class="fa fa-check"></i><b>11.2.1</b> Example: Goodness of Fit Test</a></li>
<li class="chapter" data-level="11.2.2" data-path="chi-square-and-anova-tests.html"><a href="chi-square-and-anova-tests.html#homework-29"><i class="fa fa-check"></i><b>11.2.2</b> Homework</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="chi-square-and-anova-tests.html"><a href="chi-square-and-anova-tests.html#analysis-of-variance-anova"><i class="fa fa-check"></i><b>11.3</b> Analysis of Variance (ANOVA)</a><ul>
<li class="chapter" data-level="11.3.1" data-path="chi-square-and-anova-tests.html"><a href="chi-square-and-anova-tests.html#example-hypothesis-test-involving-several-means"><i class="fa fa-check"></i><b>11.3.1</b> Example: Hypothesis Test Involving Several Means</a></li>
<li class="chapter" data-level="11.3.2" data-path="chi-square-and-anova-tests.html"><a href="chi-square-and-anova-tests.html#homework-30"><i class="fa fa-check"></i><b>11.3.2</b> Homework</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/StatPREP/Stat_using_technology" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Statistics Using Technology</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="one-sample-inference" class="section level1">
<h1><span class="header-section-number">Chapter 7</span> One-Sample Inference</h1>
<p>Now that you have all this information about descriptive statistics and probabilities, it is time to start inferential statistics. There are two branches of inferential statistics: hypothesis testing and confidence intervals.</p>
<p><strong>Hypothesis Testing:</strong> making a decision about a parameter(s) based on a statistic(s).</p>
<p><strong>Confidence Interval:</strong> estimating a parameter(s) based on a statistic(s).</p>
<p>This chapter will describe hypothesis testing, but as was stated in Chapter 1, the American Statistical Association (ASA) is suggesting not discussing statistical significance and p-values. So this chapter is mostly for background to understand previously published studies.</p>
<div id="basics-of-hypothesis-testing" class="section level2">
<h2><span class="header-section-number">7.1</span> Basics of Hypothesis Testing</h2>
<p>To understand the process of a hypothesis tests, you need to first have an understanding of what a hypothesis is, which is an educated guess about a parameter. Once you have the hypothesis, you collect data and use the data to make a determination to see if there is enough evidence to show that the hypothesis is true. However, in hypothesis testing you actually assume something else is true, and then you look at your data to see how likely it is to get an event that your data demonstrates with that assumption. If the event is very unusual, then you might think that your assumption is actually false. If you are able to say this assumption is false, then your hypothesis must be true. This is known as a proof by contradiction. You assume the opposite of your hypothesis is true and show that it canâ€™t be true. If this happens, then your hypothesis must be true. All hypothesis tests go through the same process. Once you have the process down, then the concept is much easier. It is easier to see the process by looking at an example. Concepts that are needed will be detailed in this example.</p>
<div id="example-basics-of-hypothesis-testing" class="section level3">
<h3><span class="header-section-number">7.1.1</span> Example: Basics of Hypothesis Testing</h3>
<p>Suppose a manufacturer of the XJ35 battery claims the mean life of the battery is 500 days with a standard deviation of 25 days. You are the buyer of this battery and you think this claim is incorrect. You would like to test your belief because without a good reason you canâ€™t get out of your contract.</p>
<p><strong>Solution</strong>
What do you do?</p>
<p>Well first, you should know what you are trying to measure. Define the random variable.</p>
<p>Let <em>x</em> = life of a XJ35 battery</p>
<p>Now you are not just trying to find different <em>x</em> values. You are trying to find what the true mean is. Since you are trying to find it, it must be unknown. You donâ€™t think it is 500 days. If you did, you wouldnâ€™t be doing any testing. The true mean, <span class="math inline">\(\mu\)</span>, is unknown. That means you should define that too.</p>
<p>Let <span class="math inline">\(\mu\)</span> = mean life of a XJ35 battery</p>
<p>Now what?</p>
<p>You may want to collect a sample. What kind of sample?</p>
<p>You could ask the manufacturers to give you batteries, but there is a chance that there could be some bias in the batteries they pick. To reduce the chance of bias, it is best to take a random sample.</p>
<p>How big should the sample be?</p>
<p>A sample of size 30 or more means that you can use the central limit theorem. Pick a sample of size 50.</p>
<p>Table #7.1.1 contains the data for the sample you collected:</p>
<p><strong>Table #7.1.1: Data on Battery Life</strong></p>
<div class="sourceCode" id="cb297"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb297-1"><a href="one-sample-inference.html#cb297-1"></a>Battery&lt;-<span class="st"> </span><span class="kw">read.csv</span>(</span>
<span id="cb297-2"><a href="one-sample-inference.html#cb297-2"></a>  <span class="st">&quot;https://krkozak.github.io/MAT160/battery.csv&quot;</span>)</span>
<span id="cb297-3"><a href="one-sample-inference.html#cb297-3"></a><span class="kw">head</span>(Battery)</span></code></pre></div>
<pre><code>##   life
## 1  491
## 2  485
## 3  503
## 4  492
## 5  482
## 6  490</code></pre>
<p>Now what should you do? Looking at the data set, you see some of the times are above 500 and some are below. But looking at all of the numbers is too difficult. It might be helpful to calculate the mean for this sample.</p>
<div class="sourceCode" id="cb299"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb299-1"><a href="one-sample-inference.html#cb299-1"></a><span class="kw">df_stats</span>(<span class="op">~</span>life, <span class="dt">data=</span>Battery, mean)</span></code></pre></div>
<pre><code>##   response mean
## 1     life  490</code></pre>
<p>The sample mean is 491.42 days. Looking at the sample mean, one might think that you are right. However, the standard deviation and the sample size also plays a role, so maybe you are wrong.</p>
<p>Before going any farther, it is time to formalize a few definitions.</p>
<p>You have a guess that the mean life of a battery is not 500 days. This is opposed to what the manufacturer claims. There really are two hypotheses, which are just guesses here â€“ the one that the manufacturer claims and the one that you believe. It is helpful to have names for them.</p>
<p><strong>Null Hypothesis</strong>: historical value, claim, or product specification. The symbol used is <span class="math inline">\(H_o\)</span>.</p>
<p><strong>Alternate Hypothesis:</strong> what you want to prove. This is what you want to accept as true when you reject the null hypothesis. There are two symbols that are commonly used for the alternative hypothesis: <span class="math inline">\(H_a\)</span> or <span class="math inline">\(H_1\)</span>. The symbol <span class="math inline">\(H_a\)</span> will be used in this book.</p>
<p>In general, the hypotheses look something like this:</p>
<p><span class="math inline">\(H_0:\mu=\mu_o\)</span></p>
<p><span class="math inline">\(H_a:\mu\ne \mu_o\)</span></p>
<p>where <span class="math inline">\(\mu_o\)</span> just represents the value that the claim says the population mean is actually equal to.</p>
<p>Also, <span class="math inline">\(H_o\)</span> can be less than, greater than, or not equal to, though not equal to is more common these days.</p>
<p>For this problem:</p>
<p><span class="math inline">\(H_o:\mu=500days\)</span>, since the manufacturer says the mean life of a battery is 500 days.</p>
<p><span class="math inline">\(H_a:\mu\ne 500days\)</span>, since you believe that the mean life of the battery is not 500 days.</p>
<p>Now back to the mean. You have a sample mean of 491.42 days. Is this different enough to believe that you are right and the manufacturer is wrong? How different does it have to be?</p>
<p>If you calculated a sample mean of 235 or 690, you would definitely believe the population mean is not 500. But even if you had a sample mean of 435 or 575 you would probably believe that the true mean was not 500. What about 475? or 535? Or 483? or 514? There is some point where you would stop being so sure that the population mean is not 500. That point separates the values of where you are sure or pretty sure that the mean is not 500 from the area where you are not so sure. How do you find that point?</p>
<p>Well it depends on how much error you want to make. Of course you donâ€™t want to make any errors, but unfortunately that is unavoidable in statistics. You need to figure out how much error you made with your sample. Take the sample mean, and find the probability of getting another sample mean less than it, assuming for the moment that the manufacturer is right. The idea behind this is that you want to know what is the chance that you could have come up with your sample mean even if the population mean really is 500 days.</p>
<p>Chances are probabilities. So you want to find the probability that the sample mean of 491.42 is unusual given that the population mean is really 500 days. To compute this probability, you need to know how the sample mean is distributed. Since the sample size is at least 30, then you know the sample mean is approximately normally distributed. Now, you want to find the z-value. The z-value is <span class="math inline">\(z=\frac{491.42-500}{\frac{25}{\sqrt{50}}}=-2.43\)</span>.</p>
<p>This is more than 2 standard deviations below the mean, so that seems that the sample mean is usual. It might be helpful to find the probability though. Since you are saying that the sample mean is different from 500 days, then you are asking if it is greater than or less than. This means that you are in the tails of the normal curve. So the probability you want to find is the probability being more than 2.43 or less than <span class="math inline">\(-2.43\)</span>. This is <span class="math inline">\(P(-2.43&lt;z)+P(z&gt;2.43)=0.015\)</span></p>
<div class="sourceCode" id="cb301"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb301-1"><a href="one-sample-inference.html#cb301-1"></a><span class="kw">pnorm</span>(<span class="op">-</span><span class="fl">2.43</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="dt">lower.tail=</span><span class="ot">TRUE</span>)<span class="op">+</span><span class="kw">pnorm</span>(<span class="fl">2.43</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="dt">lower.tail=</span><span class="ot">FALSE</span>)</span></code></pre></div>
<pre><code>## [1] 0.01509882</code></pre>
<p>So the probability of being in the tails is 0.015. This probability is known as a p-value for probability-value. This is unusual, so it is unlikely to get a sample mean of 491.42 if the population mean is 500 days.</p>
<p>So it appears the assumption that the population mean is 500 days is wrong, and you can reject the manufacturerâ€™s claim.</p>
<p>But how do you quantify really small? Is 5% or 10% or 15% really small? How do you decide?</p>
<p>Before you answer that question, a couple more definitions are needed.</p>
<p><strong>Test statistic:</strong> <span class="math inline">\(z=\frac{\bar{x}-\mu_o}{\frac{\sigma}{\sqrt{n}}}\)</span> since it is calculated as part of the testing of the hypothesis</p>
<p><strong>p - value:</strong> probability that the test statistic will take on more extreme values than the observed test statistic, given that the null hypothesis is true. It is the probability that was calculated above.</p>
<p>Now, how small is small enough? To answer that, you really want to know the types of errors you can make.</p>
<p>There are actually only two errors that can be made. The first error is if you say that is false, when in fact it is true. This means you reject when was true. The second error is if you say that is true, when in fact it is false. This means you fail to reject when is false. The following table organizes this for you:</p>
<p>Type of errors:</p>
<table>
<thead>
<tr class="header">
<th></th>
<th align="left">true</th>
<th align="left">false</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Reject</td>
<td align="left">Type I error</td>
<td align="left">No error</td>
</tr>
<tr class="even">
<td>Fail to reject</td>
<td align="left">No error</td>
<td align="left">Type II error</td>
</tr>
</tbody>
</table>
<p>Thus</p>
<p><strong>Type I Error</strong> is rejecting <span class="math inline">\(H_o\)</span> when <span class="math inline">\(H_o\)</span> is true, and</p>
<p><strong>Type II Error</strong> is failing to reject <span class="math inline">\(H_o\)</span> when is <span class="math inline">\(H_o\)</span> false.</p>
<p>Since these are the errors, then one can define the probabilities attached to each error.</p>
<p><span class="math inline">\(\alpha\)</span>= P(type I error) = P(rejecting <span class="math inline">\(H_o\)</span> given it is true)</p>
<p><span class="math inline">\(\beta\)</span>= P(type II error) = P(failing to reject <span class="math inline">\(H_o\)</span> given it is false)</p>
<p><span class="math inline">\(\alpha\)</span> is also called the <strong>level of significance</strong>.</p>
<p>Another common concept that is used is Power = <span class="math inline">\(1-\beta\)</span></p>
<p>Now there is a relationship between <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span>. They are not complements of each other. How are they related?</p>
<p>If <span class="math inline">\(\alpha\)</span> increases that means the chances of making a type I error will increase. It is more likely that a type I error will occur. It makes sense that you are less likely to make type II errors, only because you will be rejecting more often. You will be failing to reject less, and therefore, the chance of making a type II error will decrease. Thus, as <span class="math inline">\(\alpha\)</span> increases, <span class="math inline">\(\beta\)</span> will decrease, and vice versa. That makes them seem like complements, but they arenâ€™t complements. What gives? Consider one more factor â€“ sample size.</p>
<p>Consider if you have a larger sample that is representative of the population, then it makes sense that you have more accuracy then with a smaller sample. Think of it this way, which would you trust more, a sample mean of 490 if you had a sample size of 35 or sample size of 350 (assuming a representative sample)? Of course the 350 because there are more data points and so more accuracy. If you are more accurate, then there is less chance that you will make any error. By increasing the sample size of a representative sample, you decrease both <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span>.</p>
<p>Summary of all of this:</p>
<ol style="list-style-type: decimal">
<li><p>For a certain sample size, <em>n</em>, if <span class="math inline">\(\alpha\)</span> increases, <span class="math inline">\(\beta\)</span> decreases.</p></li>
<li><p>For a certain level of significance, <span class="math inline">\(\alpha\)</span>, if <em>n</em> increases, <span class="math inline">\(\beta\)</span> decreases.</p></li>
</ol>
<p>Now how do you find <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span>? Well <span class="math inline">\(\alpha\)</span> is actually chosen. There are only two values that are usually picked for <span class="math inline">\(\alpha\)</span>: 0.01 and 0.05. is very difficult to find <span class="math inline">\(\beta\)</span>, so usually it isnâ€™t found. If you want to make sure it is small you take as large of a sample as you can afford provided it is a representative sample. This is one use of the Power. You want to be small and the Power of the test is large. The Power word sounds good.</p>
<p>Which pick of <span class="math inline">\(\alpha\)</span> do you pick? Well that depends on what you are working on. Remember in this example you are the buyer who is trying to get out of a contract to buy these batteries. If you create a type I error, you said that the batteries are bad when they arenâ€™t, most likely the manufacturer will sue you. You want to avoid this. You might pick <span class="math inline">\(\alpha\)</span> to be 0.01. This way you have a small chance of making a type I error. Of course this means you have more of a chance of making a type II error. No big deal right? What if the batteries are used in pacemakers and you tell the person that their pacemakerâ€™s batteries are good for 500 days when they actually last less, that might be bad. If you make a type II error, you say that the batteries do last 500 days when they last less, then you have the possibility of killing someone. You certainly do not want to do this. In this case you might want to pick <span class="math inline">\(\alpha\)</span> as 0.05. If both errors are equally bad, then pick <span class="math inline">\(\alpha\)</span> as 0.05.</p>
<p>The above discussion is why the choice of depends on what you are researching. As the researcher, you are the one that needs to decide what level to use based on your analysis of the consequences of making each error is.</p>
<p>If a type I error is really bad, then pick <span class="math inline">\(\alpha\)</span>= 0.01.</p>
<p>If a type II error is really bad, then pick <span class="math inline">\(\alpha\)</span>= 0.05</p>
<p>If neither error is bad, or both are equally bad, then pick <span class="math inline">\(\alpha\)</span> = 0.05</p>
<p>Usually <span class="math inline">\(\alpha\)</span> is picked to be 0.05 in most cases.</p>
<p>The main thing is to always pick the <span class="math inline">\(\alpha\)</span> before you collect the data and start the test.</p>
<p>The above discussion was long, but it is really important information. If you donâ€™t know what the errors of the test are about, then there really is no point in making conclusions with the tests. Make sure you understand what the two errors are and what the probabilities are for them.</p>
<p>Now it is time to go back to the example and put this all together. This is the basic structure of testing a hypothesis, usually called a hypothesis test. Since this one has a test statistic involving <em>z</em>, it is also called a <em>z</em>-test. And since there is only one sample, it is usually called a one-sample <em>z</em>-test.</p>
</div>
<div id="example-battery-example-revisited." class="section level3">
<h3><span class="header-section-number">7.1.2</span> Example: Battery Example Revisited.</h3>
<ol style="list-style-type: decimal">
<li>State the random variable and the parameter in words</li>
</ol>
<p><em>x</em> = life of battery</p>
<p><span class="math inline">\(\mu\)</span> = mean life of a XJ35 battery</p>
<ol start="2" style="list-style-type: decimal">
<li>State the null and alternative hypothesis and the level of significance</li>
</ol>
<p><span class="math inline">\(H_o:\mu=500\)</span></p>
<p><span class="math inline">\(H_a:\mu\ne500\)</span></p>
<p><span class="math inline">\(\alpha\)</span> = 0.05 (from above discussion about consequences)</p>
<ol start="3" style="list-style-type: decimal">
<li>State and check the assumptions for a hypothesis test</li>
</ol>
<p>Every hypothesis has some assumptions that be met to make sure that the results of the hypothesis are valid. The assumptions are different for each test. This test has the following assumptions.</p>
<ol style="list-style-type: lower-alpha">
<li>A random sample of size <em>n</em> is taken.</li>
</ol>
<p>This occurred in this example, since it was stated that a random sample of 50 battery lives were taken.</p>
<ol start="2" style="list-style-type: lower-alpha">
<li>The population standard deviation is known.</li>
</ol>
<p>This is true, since it was given in the problem.</p>
<ol start="3" style="list-style-type: lower-alpha">
<li>The sample size is at least 30 or the population of the random variable is normally distributed.</li>
</ol>
<p>The sample size was 30, so this condition is met.</p>
<ol start="4" style="list-style-type: decimal">
<li>Find the sample statistic, test statistic, and p-value</li>
</ol>
<p>The test statistic depends on how many samples there are, what parameter you are testing, and assumptions that need to be checked. In this case, there is one sample and you are testing the mean. The assumptions were checked above.</p>
<p>Sample statistic:</p>
<div class="sourceCode" id="cb303"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb303-1"><a href="one-sample-inference.html#cb303-1"></a><span class="kw">df_stats</span>(<span class="op">~</span>life, <span class="dt">data=</span>Battery, mean)</span></code></pre></div>
<pre><code>##   response mean
## 1     life  490</code></pre>
<p>Test statistic:
The z-value is <span class="math inline">\(z=\frac{491.42-400}{\frac{25}{\sqrt{n}}}=-2.43\)</span>.</p>
<p>p-value:
<span class="math inline">\(P(-2.43&lt;z)+P(z&gt;2.43)=0.015\)</span></p>
<ol start="5" style="list-style-type: decimal">
<li>Conclusion:</li>
</ol>
<p>Now what? Well, this p-value is 0.015. This is a lot smaller than the amount of error you would accept in the problem <span class="math inline">\(\alpha\)</span> = 0.05. That means that finding a sample mean less than 490 days is unusual to happen if is true. This should make you think that is not true. You should reject <span class="math inline">\(H_o\)</span>.</p>
<p>In fact, in general:</p>
<p>Reject <span class="math inline">\(H_o\)</span> if the p-value &lt; <span class="math inline">\(\alpha\)</span></p>
<p>Fail to reject <span class="math inline">\(H_o\)</span> if the p-value <span class="math inline">\(\ge\alpha\)</span>.</p>
<ol start="6" style="list-style-type: decimal">
<li>Interpretation:</li>
</ol>
<p>Since you rejected <span class="math inline">\(H_o\)</span>, what does this mean in the real world? That it what goes in the interpretation. Since you rejected the claim by the manufacturer that the mean life of the batteries is 500 days, then you now can believe that your hypothesis was correct. In other words, there is enough evidence to support that the mean life of the battery is less than 500 days.</p>
<p>Now that you know that the batteries last less than 500 days, should you cancel the contract? Statistically, there is evidence that the batteries do not last as long as the manufacturer says they should. However, based on this sample there are only ten days less on average that the batteries last. There may not be practical significance in this case. Ten days do not seem like a large difference. In reality, if the batteries are used in pacemakers, then you would probably tell the patient to have the batteries replaced every year. You have a large buffer whether the batteries last 490 days or 500 days. It seems that it might not be worth it to break the contract over ten days. What if the 10 days was practically significant? Are there any other things you should consider? You might look at the business relationship with the manufacturer. You might also look at how much it would cost to find a new manufacturer. These are also questions to consider before making any changes. What this discussion should show you is that just because a hypothesis has statistical significance does not mean it has practical significance. The hypothesis test is just one part of a research process. There are other pieces that you need to consider.</p>
<p>Thatâ€™s it. That is what a hypothesis test looks like. All hypothesis tests are done with the same six steps. Those general six steps are outlined below.</p>
<ol style="list-style-type: decimal">
<li>State the random variable and the parameter in words. This is where
you are defining what the unknowns are in this problem.</li>
</ol>
<p>x = random variable</p>
<p><span class="math inline">\(\mu\)</span> = mean of random variable, if the parameter of interest is the mean. There are other parameters you can test, and you would use the appropriate symbol for that parameter.</p>
<ol start="2" style="list-style-type: decimal">
<li>State the null and alternative hypotheses and the level of
significance</li>
</ol>
<p><span class="math inline">\(H_o:\mu=\mu_o\)</span>, where <span class="math inline">\(\mu_o\)</span> is the known mean</p>
<p><span class="math inline">\(H_a:\mu\ne\mu_o\)</span>, You can replace <span class="math inline">\(\ne\)</span> with <span class="math inline">\(&lt;\)</span> or <span class="math inline">\(&gt;\)</span> but usually you use <span class="math inline">\(\ne\)</span></p>
<p>Also, state your level here.</p>
<ol start="3" style="list-style-type: decimal">
<li>State and check the assumptions for a hypothesis test</li>
</ol>
<p>Each hypothesis test has its own assumptions. They will be stated when the different hypothesis tests are discussed.</p>
<ol start="4" style="list-style-type: decimal">
<li>Find the sample statistic, test statistic, and p-value</li>
</ol>
<p>This depends on what parameter you are working with, how many samples, and the assumptions of the test. Technology will be used to find the sample statistic, test statistic, and p-value.</p>
<ol start="5" style="list-style-type: decimal">
<li>Conclusion</li>
</ol>
<p>This is where you write reject <span class="math inline">\(H_o\)</span> or fail to reject <span class="math inline">\(H_o\)</span>. The rule is: if the p-value <span class="math inline">\(&lt;\alpha\)</span>, then reject <span class="math inline">\(H_o\)</span>. If the p-value <span class="math inline">\(\ge\alpha\)</span>, then fail to reject <span class="math inline">\(H_o\)</span></p>
<ol start="6" style="list-style-type: decimal">
<li>Interpretation</li>
</ol>
<p>This is where you interpret in real world terms the conclusion to the test. The conclusion for a hypothesis test is that you either have enough evidence to support <span class="math inline">\(H_a\)</span>, or you do not have enough evidence to support <span class="math inline">\(H_a\)</span>.</p>
<p>Sorry, one more concept about the conclusion and interpretation. First, the conclusion is that you reject or you fail to reject <span class="math inline">\(H_o\)</span>. Why was it said like this? It is because you never <strong>accept</strong> the null hypothesis. If you wanted to accept the null hypothesis, then why do the test in the first place? In the interpretation, you either have enough evidence to support <span class="math inline">\(H_a\)</span>, or you do not have enough evidence to support <span class="math inline">\(H_a\)</span>. You wouldnâ€™t want to go to all this work and then find out you wanted to accept the claim. Why go through the trouble? You always want to have enough evidence to support the alternative hypothesis. Sometimes you can do that and sometimes you canâ€™t. If you donâ€™t have enough evidence to support <span class="math inline">\(H_a\)</span>, it doesnâ€™t mean you support the null hypothesis; it just means you canâ€™t support the alternative hypothesis. Here is an example to demonstrate this.</p>
</div>
<div id="example-conclusions-in-hypothesis-tests" class="section level3">
<h3><span class="header-section-number">7.1.3</span> Example: Conclusions in Hypothesis Tests</h3>
<p>In the U.S. court system a jury trial could be set up as a hypothesis test. To really help you see how this works, letâ€™s use OJ Simpson as an example. In the court system, a person is presumed innocent until he/she is proven guilty, and this is your null hypothesis. OJ Simpson was a football player in the 1970s. In 1994 his ex-wife and her friend were killed. OJ Simpson was accused of the crime, and in 1995 the case was tried. The prosecutors wanted to prove OJ was guilty of killing his wife and her friend, and that is the alternative hypothesis.
In this case, a verdict of not guilty was given. That does not mean that he is innocent of this crime. It means there was not enough evidence to prove he was guilty. Many people believe that OJ was guilty of this crime, but the jury did not feel that the evidence presented was enough to show there was guilt. The verdict in a jury trial is always guilty or not guilty!</p>
<p>The same is true in a hypothesis test. There is either enough or not enough evidence to support the alternative hypothesis. It is not that you proved the null hypothesis true.</p>
<p>When identifying hypothesis, it is important to state your random variable and the appropriate parameter you want to make a decision about. If you count something, then the random variable is the number of whatever you counted. The parameter is the proportion of what you counted. If the random variable is something you measured, then the parameter is the mean of what you measured. (Note: there are other parameters you can calculate, and some analysis of those will be presented in later chapters.)</p>
</div>
<div id="example-stating-hypotheses" class="section level3">
<h3><span class="header-section-number">7.1.4</span> Example: Stating Hypotheses</h3>
<p>Identify the hypotheses necessary to test the following statements:</p>
<ol style="list-style-type: lower-alpha">
<li>The average salary of a teacher is different from $30,000.</li>
</ol>
<p><strong>Solution:</strong></p>
<p><em>x</em> = salary of teacher</p>
<p><span class="math inline">\(\mu=\)</span> mean salary of teacher</p>
<p>The guess is that <span class="math inline">\(\mu\ne30000\)</span> and that is the alternative hypothesis.</p>
<p>The null hypothesis has the same parameter and number with an equal sign.</p>
<p><span class="math inline">\(H_o:\mu=30000\)</span>
<span class="math inline">\(H_a:\mu\ne30000\)</span></p>
<ol start="2" style="list-style-type: lower-alpha">
<li>The proportion of students who like math is not 10%.</li>
</ol>
<p><strong>Solution:</strong></p>
<p><em>x</em> = number of students who like math</p>
<p><em>p</em> = proportion of students who like math</p>
<p>The guess is that <em>p</em> is not 0.10 and that is the alternative hypothesis.
<span class="math inline">\(H_o:p=0.10\)</span>
<span class="math inline">\(H_a:p\ne0.10\)</span></p>
<ol start="3" style="list-style-type: lower-alpha">
<li>The average age of students in this class differs from 21.</li>
</ol>
<p><strong>Solution:</strong></p>
<p><em>x</em> = age of students in this class</p>
<p><span class="math inline">\(\mu\)</span>=mean age of students in this class</p>
<p>The guess is that <span class="math inline">\(\mu\ne21\)</span> and that is the alternative hypothesis.
<span class="math inline">\(H_o:\mu=21\)</span>
<span class="math inline">\(H_a:\mu\ne21\)</span></p>
</div>
<div id="example-stating-type-i-and-ii-errors-and-picking-level-of-significance" class="section level3">
<h3><span class="header-section-number">7.1.5</span> Example: Stating Type I and II Errors and Picking Level of Significance</h3>
<ol style="list-style-type: lower-alpha">
<li>The plant-breeding department at a major university developed a new hybrid raspberry plant called YumYum Berry. Based on research data, the claim is made that from the time shoots are planted 90 days on average are required to obtain the first berry with a standard deviation of 9.2 days. A corporation that is interested in marketing the product tests 60 shoots by planting them and recording the number of days before each plant produces its first berry. The sample mean is 92.3 days. The corporation wants to know if the mean number of days is more than the 90 days claimed. State the type I and type II errors in terms of this problem, consequences of each error, and state which level of significance to use.</li>
</ol>
<p><strong>Solution:</strong></p>
<p><em>x</em> = time to first berry for YumYum Berry plant</p>
<p>= mean time to first berry for YumYum Berry plant</p>
<p>Type I Error: If the corporation does a type I error, then they will say that the plants take longer to produce than 90 days when they donâ€™t. They probably will not want to market the plants if they think they will take longer. They will not market them even though in reality the plants do produce in 90 days. They may have loss of future earnings, but that is all.</p>
<p>Type II error: The corporation do not say that the plants take longer then 90 days to produce when they do take longer. Most likely they will market the plants. The plants will take longer, and so customers might get upset and then the company would get a bad reputation. This would be really bad for the company.</p>
<p>Level of significance: It appears that the corporation would not want to make a type II error. Pick a 5% level of significance, <span class="math inline">\(\alpha=0.05\)</span>.</p>
<ol start="2" style="list-style-type: lower-alpha">
<li>A concern was raised in Australia that the percentage of deaths of Aboriginal prisoners was higher than the percent of deaths of non-indigenous prisoners, which is 0.27%. State the type I and type II errors in terms of this problem, consequences of each error, and state which level of significance to use.</li>
</ol>
<p><strong>Solution:</strong></p>
<p>x = number of Aboriginal prisoners who have died</p>
<p><em>p</em> = proportion of Aboriginal prisoners who have died</p>
<p>Type I error: Rejecting that the proportion of Aboriginal prisoners who died was 0.27%, when in fact it was 0.27%. This would mean you would say there is a problem when there isnâ€™t one. You could anger the Aboriginal community, and spend time and energy researching something that isnâ€™t a problem.</p>
<p>Type II error: Failing to reject that the proportion of Aboriginal prisoners who died was 0.27%, when in fact it is higher than 0.27%. This would mean that you wouldnâ€™t think there was a problem with Aboriginal prisoners dying when there really is a problem. You risk causing deaths when there could be a way to avoid them.</p>
<p>Level of significance: It appears that both errors may be issues in this case. You wouldnâ€™t want to anger the Aboriginal community when there isnâ€™t an issue, and you wouldnâ€™t want people to die when there may be a way to stop it. It may be best to pick a 5% level of significance, <span class="math inline">\(\alpha=0.05\)</span>.</p>
<p>Hint â€“ hypothesis testing is really easy if you follow the same recipe every time. The only differences in the various problems are the assumptions of the test and the test statistic you calculate so you can find the p-value. Do the same steps, in the same order, with the same words, every time and these problems become very easy.</p>
</div>
<div id="homework-16" class="section level3">
<h3><span class="header-section-number">7.1.6</span> Homework</h3>
<p><strong>For the problems in this section, a question is being asked. This is to help you understand what the hypotheses are. You are not to run any hypothesis tests nor come up with any conclusions in this section.</strong></p>
<ol style="list-style-type: decimal">
<li><p>The Arizona Republic/Morrison/Cronkite News poll published on Monday, October 20, 2016, found 390 of the registered voters surveyed favor Proposition 205, which would legalize marijuana for adults. The statewide telephone poll surveyed 779 registered voters between Oct.Â 10 and Oct.Â 15. (Sanchez, 2016) Fifty-five percent of Colorado residents supported the legalization of marijuana. Does the data provide evidence that the percentage of Arizona residents who support legalization of marijuana is different from the proportion of Colorado residents who support it. State the random variable, population parameter, and hypotheses.</p></li>
<li><p>According to the February 2008 Federal Trade Commission report on consumer fraud and identity theft, 23% of all complaints in 2007 were for identity theft. In that year, Alaska had 321 complaints of identity theft out of 1,432 consumer complaints ("Consumer fraud and," 2008). Does this data provide enough evidence to show that Alaska had a different proportion of identity theft than 23%? State the random variable, population parameter, and hypotheses.</p></li>
<li><p>The Kyoto Protocol was signed in 1997, and required countries to start reducing their carbon emissions. The protocol became enforceable in February 2005. In 2004, the mean CO2 emission was 4.87 metric tons per capita. Is there enough evidence to show that the mean CO2 emission is different in 2010 than in 2004? State the random variable, population parameter, and hypotheses.</p></li>
<li><p>The FDA regulates that fish that is consumed is allowed to contain 1.0 mg/kg of mercury. In Florida, bass fish were collected in 53 different lakes to measure the amount of mercury in the fish. Do the data provide enough evidence to show that the fish in Florida lakes has a different amount of mercury than the allowable amount? State the random variable, population parameter, and hypotheses.</p></li>
<li><p>The Arizona Republic/Morrison/Cronkite News poll published on Monday, October 20, 2016, found 390 of the registered voters surveyed favor Proposition 205, which would legalize marijuana for adults. The statewide telephone poll surveyed 779 registered voters between Oct.Â 10 and Oct.Â 15. (Sanchez, 2016) Fifty-five percent of Colorado residents supported the legalization of marijuana. Does the data provide evidence that the percentage of Arizona residents who support legalization of marijuana is different from the proportion of Colorado residents who support it. State the type I and type II errors in this case, consequences of each error type for this situation from the perspective of the manufacturer, and the appropriate alpha level to use. State why you picked this alpha level.</p></li>
<li><p>According to the February 2008 Federal Trade Commission report on consumer fraud and identity theft, 23% of all complaints in 2007 were for identity theft. In that year, Alaska had 321 complaints of identity theft out of 1,432 consumer complaints ("Consumer fraud and," 2008). Does this data provide enough evidence to show that Alaska had a different proportion of identity theft than 23%? State the type I and type II errors in this case, consequences of each error type for this situation from the perspective of the state of Alaska, and the appropriate alpha level to use. State why you picked this alpha level.</p></li>
<li><p>The Kyoto Protocol was signed in 1997, and required countries to start reducing their carbon emissions. The protocol became enforceable in February 2005. In 2004, the mean CO2 emission was 4.87 metric tons per capita. Is there enough evidence to show that the mean CO2 emission is lower in 2010 than in 2004? State the type I and type II errors in this case, consequences of each error type for this situation from the perspective of the agency overseeing the protocol, and the appropriate alpha level to use. State why you picked this alpha level.</p></li>
<li><p>The FDA regulates that fish that is consumed is allowed to contain 1.0 mg/kg of mercury. In Florida, bass fish were collected in 53 different lakes to measure the amount of mercury in the fish. Do the data provide enough evidence to show that the fish in Florida lakes has different amount of mercury than the allowable amount? State the type I and type II errors in this case, consequences of each error type for this situation from the perspective of the FDA, and the appropriate alpha level to use. State why you picked this alpha level.</p></li>
</ol>
<p><strong><br />
</strong></p>
</div>
</div>
<div id="one-sample-proportion-test" class="section level2">
<h2><span class="header-section-number">7.2</span> One-Sample Proportion Test</h2>
<p>There are many different parameters that you can test. There is a test for the mean, such as was introduced with the z-test. There is also a test for the population proportion, <em>p</em>. This is where you might be curious if the proportion of students who smoke at your school is lower than the proportion in your area. Or you could question if the proportion of accidents caused by teenage drivers who do not have a driversâ€™ education class is more than the national proportion.</p>
<p>To test a population proportion, there are a few things that need to be defined first. Usually, Greek letters are used for parameters and Latin letters for statistics. When talking about proportions, it makes sense to use <em>p</em> for proportion. The Greek letter for <em>p</em> is <span class="math inline">\(\pi\)</span>, but that is too confusing to use. Instead, it is best to use <em>p</em> for the population proportion. That means that a different symbol is needed for the sample proportion. The convention is to use, <span class="math inline">\(\hat{p}\)</span>, known as p-hat. This way you know that <em>p</em> is the population proportion, and that <span class="math inline">\(\hat{p}\)</span> is the sample proportion related to it.</p>
<p>Now proportion tests are about looking for the percentage of individuals who have a particular attribute. You are really looking for the number of successes that happen. Thus, a proportion test involves a binomial distribution.</p>
<p><strong>Hypothesis Test for One Population Proportion (1-Prop Test)</strong></p>
<ol style="list-style-type: decimal">
<li>State the random variable and the parameter in words.</li>
</ol>
<p>x = number of successes</p>
<p><em>p</em> = proportion of successes</p>
<ol start="2" style="list-style-type: decimal">
<li>State the null and alternative hypotheses and the level of
significance</li>
</ol>
<p><span class="math inline">\(H_o:p=p_o\)</span>, where <span class="math inline">\(p_o\)</span> is the known proportion</p>
<p><span class="math inline">\(H_a:p\ne p_o\)</span>, you can also use &lt; or &gt;, but <span class="math inline">\(\ne\)</span> is the more common one to use.</p>
<p>Also, state your <span class="math inline">\(\alpha\)</span> level here.</p>
<ol start="3" style="list-style-type: decimal">
<li>State and check the assumptions for a hypothesis test</li>
</ol>
<ol style="list-style-type: lower-alpha">
<li><p>State: A simple random sample of size <em>n</em> is taken. Check: describe how the sample was collected</p></li>
<li><p>State: The conditions for the binomial experiment are satisfied. Check: Show all four properties are true.</p></li>
<li><p>State: The sampling distribution of <span class="math inline">\(\hat{p}\)</span> is normally distributed. Check: you need to show that <span class="math inline">\(p*n\ge5\)</span> and <span class="math inline">\(q*n\ge5\)</span>, where <span class="math inline">\(q=1-p\)</span>. If this requirement is true, then the sampling distribution of <span class="math inline">\(\hat{p}\)</span> is well approximated by a normal curve.</p></li>
</ol>
<ol start="4" style="list-style-type: decimal">
<li>Find the sample statistic, test statistic, and p-value</li>
</ol>
<p>This will be computed on R Studio using the command</p>
<div class="sourceCode" id="cb305"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb305-1"><a href="one-sample-inference.html#cb305-1"></a><span class="kw">prop.test</span>(r, n, <span class="dt">p=</span>what Ho says)</span></code></pre></div>
<p>where r=observed number of successes and n = number of trials.</p>
<ol start="5" style="list-style-type: decimal">
<li>Conclusion</li>
</ol>
<p>This is where you write reject or fail to reject <span class="math inline">\(H_o\)</span>. The rule is: if the p-value <span class="math inline">\(&lt;\alpha\)</span> , then reject <span class="math inline">\(H_0\)</span>. If the p-value <span class="math inline">\(\ge\alpha\)</span>, then fail to reject <span class="math inline">\(H_o\)</span></p>
<ol start="6" style="list-style-type: decimal">
<li>Interpretation</li>
</ol>
<p>This is where you interpret in real world terms the conclusion to the test. The conclusion for a hypothesis test is that you either have enough evidence to support <span class="math inline">\(H_a\)</span>, or you do not have enough evidence to support <span class="math inline">\(H_a\)</span>.</p>
<div id="example-hypothesis-test-for-one-proportion" class="section level3">
<h3><span class="header-section-number">7.2.1</span> Example: Hypothesis Test for One Proportion</h3>
<p>A concern was raised in Australia that the percentage of deaths of Aboriginal prisoners was different than the percent of deaths of non-Aboriginal prisoners, which is 0.27%. A sample of six years (1990-1995) of data was collected, and it was found that out of 14,495 Aboriginal prisoners, 51 died ("Indigenous deaths in," 1996). Do the data provide enough evidence to show that the proportion of deaths of Aboriginal prisoners is different from 0.27%?</p>
<p><strong>Solution:</strong></p>
<ol style="list-style-type: decimal">
<li>State the random variable and the parameter in words.</li>
</ol>
<p><em>x</em> = number of Aboriginal prisoners who die</p>
<p><em>p</em> = proportion of Aboriginal prisoners who die</p>
<ol start="2" style="list-style-type: decimal">
<li>State the null and alternative hypotheses and the level of significance</li>
</ol>
<p><span class="math inline">\(H_o:p=0.0027\)</span></p>
<p><span class="math inline">\(H_a:p\ne0.0027\)</span></p>
<p>From Example #7.1.5, the argument was made to pick 5% for the level of significance. So <span class="math inline">\(\alpha=0.05\)</span></p>
<ol start="3" style="list-style-type: decimal">
<li>State and check the assumptions for a hypothesis test</li>
</ol>
<ol style="list-style-type: lower-alpha">
<li><p>A simple random sample of 14,495 Aboriginal prisoners was taken. Check: The sample was not a random sample, since it was data from six years. It is the numbers for all prisoners in these six years, but the six years were not picked at random. Unless there was something special about the six years that were chosen, the sample is probably a representative sample. This assumption is probably met.</p></li>
<li><p>The properties of a binomial experiment are met. There are 14,495 prisoners in this case. Check: The prisoners are all Aboriginals, so you are not mixing Aboriginal with non-Aboriginal prisoners. There are only two outcomes, either the prisoner dies or doesnâ€™t. The chance that one prisoner dies over another may not be constant, but if you consider all prisoners the same, then it may be close to the same probability. Thus the conditions for the binomial distribution are satisfied</p></li>
<li><p>The sampling distribution of <span class="math inline">\(\hat{p}\)</span> can be approximated with a normal distributed. Check: In this case <em>p</em> = 0.0027 and <em>n</em> = 14,495. <span class="math inline">\(n*p=39.1365\ge5\)</span> and <span class="math inline">\(n*q=14455.86\ge5\)</span>. So, the sampling distribution for <span class="math inline">\(\hat{p}\)</span> is normally distributed.</p></li>
</ol>
<ol start="4" style="list-style-type: decimal">
<li>Find the sample statistic, test statistic, and p-value</li>
</ol>
<p>Use the following command in R Studio:</p>
<div class="sourceCode" id="cb306"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb306-1"><a href="one-sample-inference.html#cb306-1"></a><span class="kw">prop.test</span>(<span class="dv">51</span>, <span class="dv">14495</span>, <span class="dt">p=</span><span class="fl">0.0027</span>)</span></code></pre></div>
<pre><code>## 
##  1-sample proportions test with continuity correction
## 
## data:  51 out of 14495
## X-squared = 3.3084, df = 1, p-value = 0.06893
## alternative hypothesis: true p is not equal to 0.0027
## 95 percent confidence interval:
##  0.002647440 0.004661881
## sample estimates:
##           p 
## 0.003518455</code></pre>
<p>Sample Proportion: <span class="math inline">\(\hat{p}=0.0035\)</span></p>
<p>Test Statistic: <span class="math inline">\(\chi^2=3.3085\)</span></p>
<p>p-value: <span class="math inline">\(p-value=0.06893\)</span></p>
<ol start="5" style="list-style-type: decimal">
<li>Conclusion</li>
</ol>
<p>Since the <span class="math inline">\(p-value\ge0.05\)</span>, then fail to reject <span class="math inline">\(H_o\)</span>.</p>
<ol start="6" style="list-style-type: decimal">
<li>Interpretation</li>
</ol>
<p>There is not enough evidence to support that the proportion of deaths of Aboriginal prisoners is different from non-Aboriginal prisoners.</p>
</div>
<div id="example-hypothesis-test-for-one-proportion-1" class="section level3">
<h3><span class="header-section-number">7.2.2</span> Example: Hypothesis Test for One Proportion</h3>
<p>A researcher who is studying the effects of income levels on breastfeeding of infants hypothesizes that countries with a low income level have a different rate of infant breastfeeding than higher income countries. It is known that in Germany, considered a high-income country by the World Bank, 22% of all babies are breastfeed. In Tajikistan, considered a low-income country by the World Bank, researchers found that in a random sample of 500 new mothers that 125 were breastfeeding their infant. At the 5% level of significance, does this show that low-income countries have a different incident of breastfeeding?</p>
<p><strong>Solution:</strong></p>
<ol style="list-style-type: decimal">
<li>State you random variable and the parameter in words.</li>
</ol>
<p><em>x</em> = number of woman who breastfeed in a low-income country</p>
<p><em>p</em> = proportion of woman who breastfeed in a low-income country</p>
<ol start="2" style="list-style-type: decimal">
<li>State the null and alternative hypotheses and the level of significance</li>
</ol>
<p><span class="math inline">\(H_o:p=0.22\)</span></p>
<p><span class="math inline">\(H_a:p\ne0.22\)</span></p>
<p><span class="math inline">\(\alpha=0.05\)</span></p>
<ol start="3" style="list-style-type: decimal">
<li>State and check the assumptions for a hypothesis test</li>
</ol>
<ol style="list-style-type: lower-alpha">
<li><p>A simple random sample of 500 breastfeeding habits of woman in a low-income country was taken. Check: This was stated in the problem.</p></li>
<li><p>The properties of a Binomial Experiment have been met. Check: There were 500 women in the study. The women are considered identical, though they probably have some differences. There are only two outcomes, either the woman breastfeeds or she doesnâ€™t. The probability of a woman breastfeeding is probably not the same for each woman, but it is probably not very different for each woman. The conditions for the binomial distribution are satisfied</p></li>
<li><p>The sampling distribution of <span class="math inline">\(\hat{p}\)</span> can be approximated with a normal distributed. Check: In this case, <em>n</em> = 500 and <em>p</em> = 0.22. <span class="math inline">\(n*p= 110\ge5\)</span> and <span class="math inline">\(n*q=390\ge5\)</span>, so the sampling distribution of <span class="math inline">\(\hat{p}\)</span> is well approximated by a normal curve.</p></li>
</ol>
<ol start="4" style="list-style-type: decimal">
<li>Find the sample statistic, test statistic, and p-value</li>
</ol>
<p>On R studio, use the following command</p>
<div class="sourceCode" id="cb308"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb308-1"><a href="one-sample-inference.html#cb308-1"></a><span class="kw">prop_test</span>(<span class="dv">125</span>, <span class="dv">500</span>, <span class="dt">p=</span><span class="fl">0.22</span>)</span></code></pre></div>
<pre><code>## 
##  1-sample proportions test with continuity correction
## 
## data:  125 out of 500
## X-squared = 2.4505, df = 1, p-value = 0.1175
## alternative hypothesis: true p is not equal to 0.22
## 95 percent confidence interval:
##  0.2131062 0.2908059
## sample estimates:
##    p 
## 0.25</code></pre>
<p>Sample Statistic: <span class="math inline">\(\hat{p}=0.25\)</span>
test Statistic: <span class="math inline">\(\chi^2=2.4505\)</span>
p-value: <span class="math inline">\(p-value=0.1175\)</span></p>
<ol start="5" style="list-style-type: decimal">
<li>Conclusion</li>
</ol>
<p>Since the p-value is more than 0.05, you fail to reject <span class="math inline">\(H_o\)</span>.</p>
<ol start="6" style="list-style-type: decimal">
<li>Interpretation</li>
</ol>
<p>There is not enough evidence to support that the proportion of women who breastfeed in low-income countries is different from the proportion of women in high-income countries who breastfeed.</p>
<p>Notice, the conclusion is that there wasnâ€™t enough evidence to support <span class="math inline">\(H_a\)</span>. The conclusion was not that you support <span class="math inline">\(H_o\)</span>. There are many reasons why you canâ€™t say that <span class="math inline">\(H_o\)</span> is true. It could be that the countries you chose were not very representative of what truly happens. If you instead looked at all high-income countries and compared them to low-income countries, you might have different results. It could also be that the sample you collected in the low-income country was not representative. It could also be that income level is not an indication of breastfeeding habits. It could be that the sample that was taken didnâ€™t show evidence but another sample would show evidence. There could be other factors involved. This is why you canâ€™t say that you support <span class="math inline">\(H_o\)</span>. There are too many other factors that could be the reason that you failed to reject <span class="math inline">\(H_0\)</span>.</p>
</div>
<div id="homework-17" class="section level3">
<h3><span class="header-section-number">7.2.3</span> Homework</h3>
<p><strong>In each problem show all steps of the hypothesis test. If some of the assumptions are not met, note that the results of the test may not be correct and then continue the process of the hypothesis test.</strong></p>
<ol style="list-style-type: decimal">
<li><p>The Arizona Republic/Morrison/Cronkite News poll published on Monday, October 20, 2016, found 390 of the registered voters surveyed favor Proposition 205, which would legalize marijuana for adults. The statewide telephone poll surveyed 779 registered voters between Oct.Â 10 and Oct.Â 15. (Sanchez, 2016) Fifty-five percent of Colorado residents supported the legalization of marijuana. Does the data provide evidence that the percentage of Arizona residents who support legalization of marijuana is different from the proportion of Colorado residents who support it. Test at the 1% level.</p></li>
<li><p>In July of 1997, Australians were asked if they thought unemployment would increase, and 47% thought that it would increase. In November of 1997, they were asked again. At that time 284 out of 631 said that they thought unemployment would increase ("Morgan Gallup poll," 2013). At the 5% level, is there enough evidence to show that the proportion of Australians in November 1997 who believe unemployment would increase is different from the proportion who felt it would increase in July 1997?</p></li>
<li><p>According to the February 2008 Federal Trade Commission report on consumer fraud and identity theft, 23% of all complaints in 2007 were for identity theft. In that year, Arkansas had 1,601 complaints of identity theft out of 3,482 consumer complaints ("Consumer fraud and," 2008). Does this data provide enough evidence to show that Arkansas had a different percentage of identity theft than 23%? Test at the 5% level.</p></li>
<li><p>According to the February 2008 Federal Trade Commission report on consumer fraud and identity theft, 23% of all complaints in 2007 were for identity theft. In that year, Alaska had 321 complaints of identity theft out of 1,432 consumer complaints ("Consumer fraud and," 2008). Does this data provide enough evidence to show that Alaska had a different proportion of identity theft than 23%? Test at the 5% level.</p></li>
<li><p>In 2001, the Gallup poll found that 81% of American adults believed that there was a conspiracy in the death of President Kennedy. In 2013, the Gallup poll asked 1,039 American adults if they believe there was a conspiracy in the assassination, and found that 634 believe there was a conspiracy ("Gallup news service," 2013). Do the data show that the proportion of Americans who believe in this conspiracy has changed? Test at the 1% level.</p></li>
<li><p>In 2008, there were 507 children in Arizona out of 32,601 who were diagnosed with Autism Spectrum Disorder (ASD) ("Autism and developmental," 2008). Nationally 1 in 88 children are diagnosed with ASD ("CDC features -," 2013). Is there sufficient data to show that the incident of ASD is different in Arizona than nationally? Test at the 1% level.</p></li>
</ol>
<p><strong><br />
</strong></p>
</div>
</div>
<div id="one-sample-test-for-the-mean" class="section level2">
<h2><span class="header-section-number">7.3</span> One-Sample Test for the Mean</h2>
<p>It is time to go back to look at the test for the mean that was introduced in section 7.1 called the z-test. In the example, you knew what the population standard deviation, <span class="math inline">\(\sigma\)</span>, was. What if you donâ€™t know <span class="math inline">\(\sigma\)</span>?</p>
<p>If you donâ€™t know <span class="math inline">\(\sigma\)</span>, then you donâ€™t know the sampling distribution of the mean. Can it be found another way? The answer is of course, yes. One way is to use a method called resampling. The following example explains how resampling is performed.</p>
<div id="example-resampling" class="section level3">
<h3><span class="header-section-number">7.3.1</span> Example: Resampling</h3>
<p>A random sample of 10 body mass index (BMI) were taken from the NHANES Data frame The mean BMI of Australians is 27.2 <span class="math inline">\(kg/m^2\)</span>. Is there evidence that Americans have a different BMI from people in Australia. Test at the 5% level.</p>
<p><strong>Solution</strong>
The standard deviation of BMI is not known for Australians. To answer this questions, first look at the sample from NHANES.</p>
<p>** Table 7.3.1: Sample of size 10 from NHANES data frame **</p>
<div class="sourceCode" id="cb310"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb310-1"><a href="one-sample-inference.html#cb310-1"></a>sample_NHANES_<span class="dv">10</span>&lt;-</span>
<span id="cb310-2"><a href="one-sample-inference.html#cb310-2"></a><span class="st">  </span><span class="kw">sample_n</span>(NHANES, <span class="dt">size=</span><span class="dv">10</span>)</span>
<span id="cb310-3"><a href="one-sample-inference.html#cb310-3"></a>sample_NHANES_<span class="dv">10</span></span></code></pre></div>
<pre><code>## # A tibble: 10 Ã— 76
##       ID SurveyYr Gender   Age AgeDecade AgeMonths Race1   
##    &lt;int&gt; &lt;fct&gt;    &lt;fct&gt;  &lt;int&gt; &lt;fct&gt;         &lt;int&gt; &lt;fct&gt;   
##  1 55003 2009_10  male      54 &quot; 50-59&quot;        659 White   
##  2 57236 2009_10  female    19 &quot; 10-19&quot;        228 White   
##  3 65433 2011_12  female    60 &quot; 60-69&quot;         NA White   
##  4 52734 2009_10  female    28 &quot; 20-29&quot;        345 White   
##  5 54061 2009_10  male      25 &quot; 20-29&quot;        309 Black   
##  6 58956 2009_10  male      13 &quot; 10-19&quot;        158 Black   
##  7 59977 2009_10  male      44 &quot; 40-49&quot;        530 White   
##  8 60373 2009_10  male      40 &quot; 40-49&quot;        490 Hispanic
##  9 56248 2009_10  female    65 &quot; 60-69&quot;        781 Black   
## 10 66547 2011_12  male      65 &quot; 60-69&quot;         NA White   
## # â€¦ with 69 more variables: Race3 &lt;fct&gt;, Education &lt;fct&gt;,
## #   MaritalStatus &lt;fct&gt;, HHIncome &lt;fct&gt;, HHIncomeMid &lt;int&gt;,
## #   Poverty &lt;dbl&gt;, HomeRooms &lt;int&gt;, HomeOwn &lt;fct&gt;,
## #   Work &lt;fct&gt;, Weight &lt;dbl&gt;, Length &lt;dbl&gt;, HeadCirc &lt;dbl&gt;,
## #   Height &lt;dbl&gt;, BMI &lt;dbl&gt;, BMICatUnder20yrs &lt;fct&gt;,
## #   BMI_WHO &lt;fct&gt;, Pulse &lt;int&gt;, BPSysAve &lt;int&gt;,
## #   BPDiaAve &lt;int&gt;, BPSys1 &lt;int&gt;, BPDia1 &lt;int&gt;,
## #   BPSys2 &lt;int&gt;, BPDia2 &lt;int&gt;, BPSys3 &lt;int&gt;, BPDia3 &lt;int&gt;,
## #   Testosterone &lt;dbl&gt;, DirectChol &lt;dbl&gt;, TotChol &lt;dbl&gt;,
## #   UrineVol1 &lt;int&gt;, UrineFlow1 &lt;dbl&gt;, UrineVol2 &lt;int&gt;,
## #   UrineFlow2 &lt;dbl&gt;, Diabetes &lt;fct&gt;, DiabetesAge &lt;int&gt;,
## #   HealthGen &lt;fct&gt;, DaysPhysHlthBad &lt;int&gt;,
## #   DaysMentHlthBad &lt;int&gt;, LittleInterest &lt;fct&gt;,
## #   Depressed &lt;fct&gt;, nPregnancies &lt;int&gt;, nBabies &lt;int&gt;,
## #   Age1stBaby &lt;int&gt;, SleepHrsNight &lt;int&gt;,
## #   SleepTrouble &lt;fct&gt;, PhysActive &lt;fct&gt;,
## #   PhysActiveDays &lt;int&gt;, TVHrsDay &lt;fct&gt;, CompHrsDay &lt;fct&gt;,
## #   TVHrsDayChild &lt;int&gt;, CompHrsDayChild &lt;int&gt;,
## #   Alcohol12PlusYr &lt;fct&gt;, AlcoholDay &lt;int&gt;,
## #   AlcoholYear &lt;int&gt;, SmokeNow &lt;fct&gt;, Smoke100 &lt;fct&gt;,
## #   Smoke100n &lt;fct&gt;, SmokeAge &lt;int&gt;, Marijuana &lt;fct&gt;,
## #   AgeFirstMarij &lt;int&gt;, RegularMarij &lt;fct&gt;,
## #   AgeRegMarij &lt;int&gt;, HardDrugs &lt;fct&gt;, SexEver &lt;fct&gt;,
## #   SexAge &lt;int&gt;, SexNumPartnLife &lt;int&gt;,
## #   SexNumPartYear &lt;int&gt;, SameSex &lt;fct&gt;,
## #   SexOrientation &lt;fct&gt;, PregnantNow &lt;fct&gt;</code></pre>
<p>The mean BMI from this sample is</p>
<div class="sourceCode" id="cb312"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb312-1"><a href="one-sample-inference.html#cb312-1"></a><span class="kw">df_stats</span>(<span class="op">~</span>BMI, <span class="dt">data=</span>sample_NHANES_<span class="dv">10</span>, mean)</span></code></pre></div>
<pre><code>##   response   mean
## 1      BMI 30.922</code></pre>
<p>The sample mean for Americans is different from the mean BMI for Australians, but could it just be by chance. Suppose you take another sample of size 10, but you only have these 10 BMIs to work with. So how could you do this. One way is to assume that the sample you took is representative of the entire population, and so you create a population by copying this sample over and over again. So you could have over 1000 copies of this sample of 10 BMIs. Then take a sample of size 10 from this created population. When doing this, you could conceivably choose the same number several times that was in the original sample and not choose some of the numbers that were in the original sample. Instead of physically creating this new population, you could just take samples from your original sample but with replacement. This means that you randomly pick the first number, record it, and then put it back that value back before collecting the next number. This kind a sampling is called randomization sampling. A sample using randomization could be</p>
<p>Table #7.3.1a</p>
<div class="sourceCode" id="cb314"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb314-1"><a href="one-sample-inference.html#cb314-1"></a><span class="kw">resample</span>(sample_NHANES_<span class="dv">10</span>)</span></code></pre></div>
<pre><code>## # A tibble: 10 Ã— 77
##       ID SurveyYr Gender   Age AgeDecade AgeMonths Race1
##    &lt;int&gt; &lt;fct&gt;    &lt;fct&gt;  &lt;int&gt; &lt;fct&gt;         &lt;int&gt; &lt;fct&gt;
##  1 65433 2011_12  female    60 &quot; 60-69&quot;         NA White
##  2 65433 2011_12  female    60 &quot; 60-69&quot;         NA White
##  3 59977 2009_10  male      44 &quot; 40-49&quot;        530 White
##  4 59977 2009_10  male      44 &quot; 40-49&quot;        530 White
##  5 57236 2009_10  female    19 &quot; 10-19&quot;        228 White
##  6 65433 2011_12  female    60 &quot; 60-69&quot;         NA White
##  7 59977 2009_10  male      44 &quot; 40-49&quot;        530 White
##  8 54061 2009_10  male      25 &quot; 20-29&quot;        309 Black
##  9 57236 2009_10  female    19 &quot; 10-19&quot;        228 White
## 10 52734 2009_10  female    28 &quot; 20-29&quot;        345 White
## # â€¦ with 70 more variables: Race3 &lt;fct&gt;, Education &lt;fct&gt;,
## #   MaritalStatus &lt;fct&gt;, HHIncome &lt;fct&gt;, HHIncomeMid &lt;int&gt;,
## #   Poverty &lt;dbl&gt;, HomeRooms &lt;int&gt;, HomeOwn &lt;fct&gt;,
## #   Work &lt;fct&gt;, Weight &lt;dbl&gt;, Length &lt;dbl&gt;, HeadCirc &lt;dbl&gt;,
## #   Height &lt;dbl&gt;, BMI &lt;dbl&gt;, BMICatUnder20yrs &lt;fct&gt;,
## #   BMI_WHO &lt;fct&gt;, Pulse &lt;int&gt;, BPSysAve &lt;int&gt;,
## #   BPDiaAve &lt;int&gt;, BPSys1 &lt;int&gt;, BPDia1 &lt;int&gt;,
## #   BPSys2 &lt;int&gt;, BPDia2 &lt;int&gt;, BPSys3 &lt;int&gt;, BPDia3 &lt;int&gt;,
## #   Testosterone &lt;dbl&gt;, DirectChol &lt;dbl&gt;, TotChol &lt;dbl&gt;,
## #   UrineVol1 &lt;int&gt;, UrineFlow1 &lt;dbl&gt;, UrineVol2 &lt;int&gt;,
## #   UrineFlow2 &lt;dbl&gt;, Diabetes &lt;fct&gt;, DiabetesAge &lt;int&gt;,
## #   HealthGen &lt;fct&gt;, DaysPhysHlthBad &lt;int&gt;,
## #   DaysMentHlthBad &lt;int&gt;, LittleInterest &lt;fct&gt;,
## #   Depressed &lt;fct&gt;, nPregnancies &lt;int&gt;, nBabies &lt;int&gt;,
## #   Age1stBaby &lt;int&gt;, SleepHrsNight &lt;int&gt;,
## #   SleepTrouble &lt;fct&gt;, PhysActive &lt;fct&gt;,
## #   PhysActiveDays &lt;int&gt;, TVHrsDay &lt;fct&gt;, CompHrsDay &lt;fct&gt;,
## #   TVHrsDayChild &lt;int&gt;, CompHrsDayChild &lt;int&gt;,
## #   Alcohol12PlusYr &lt;fct&gt;, AlcoholDay &lt;int&gt;,
## #   AlcoholYear &lt;int&gt;, SmokeNow &lt;fct&gt;, Smoke100 &lt;fct&gt;,
## #   Smoke100n &lt;fct&gt;, SmokeAge &lt;int&gt;, Marijuana &lt;fct&gt;,
## #   AgeFirstMarij &lt;int&gt;, RegularMarij &lt;fct&gt;,
## #   AgeRegMarij &lt;int&gt;, HardDrugs &lt;fct&gt;, SexEver &lt;fct&gt;,
## #   SexAge &lt;int&gt;, SexNumPartnLife &lt;int&gt;,
## #   SexNumPartYear &lt;int&gt;, SameSex &lt;fct&gt;,
## #   SexOrientation &lt;fct&gt;, PregnantNow &lt;fct&gt;, orig.id &lt;chr&gt;</code></pre>

<p>Notice that some of the unit of observations are repeated. That is what happens when you resample. Now one resampling isnâ€™t enough. So you want to resample many times so you can create a resampling distribution.</p>
<div class="figure"><span id="fig:sample-NHANES10-resample-histogram"></span>
<img src="Statistics_using_technology_files/figure-html/sample-NHANES10-resample-histogram-1.png" alt="Resampling distribution of mean BMI with sample size 10, and measured sample mean." width="672" />
<p class="caption">
Figure 7.1: Resampling distribution
</p>
</div>
<pre><code>##   response      mean      sd
## 1      mea 0.8290111 3.00108</code></pre>
<p>Notice the sample mean from the resampling is very close to 0, so that means that the US BMI are not that different from the Australian BMI. There doesnâ€™t seem to be enough evidence to show that the US BMI is different from the Australian BMI. One note, the sample size used here was 10 so you could see the sample, but really the sample size should be more than 100 for this method to be valid.</p>
<p>So this is one way to answer the question about if there is evidence to show a population mean is different from a value. This is actually the method that Ronald Fisher developed when he create all the foundation work that he did in statistics in the early 1900s. However, at the time, computers didnâ€™t exist, so taking 100 reampling samples was not possible at that time. So other methods had to be developed that could be computed during that time. One method was developed by William (W.S) Gossett, a Chemist who worked for Guinness as their head brewer. Gossett developed a distribution called the Studentâ€™s T-distribution. His process was to use the sample standard deviation, <em>s</em>, as an approximation of <span class="math inline">\(\sigma\)</span>. This means the test statistic is now <span class="math inline">\(t=\frac{x-\mu}{\frac{s}{\sqrt{n}}}\)</span>. This new test statistic is actually distributed as a Studentâ€™s t-distribution, developed by W.S. Gossett. There are some assumptions that must be made for this formula to be a Studentâ€™s t-distribution. These are outlined in the following theorem. Note: the t-distribution is called the Studentâ€™s t-distribution because that is the name he published under because he couldnâ€™t publish under his own name due to employer not wanting him to publish under his own name. His employer by the way was Guinness and they didnâ€™t want competitors knowing they had a chemist/statistician working for them. It is not called the Studentâ€™s t-distribution because it is only used by students.</p>
<p>Theorem: If the following assumptions are met</p>
<ol style="list-style-type: lower-alpha">
<li><p>A random sample of size <em>n</em> is taken.</p></li>
<li><p>The distribution of the random variable is normal.</p></li>
</ol>
<p>Then the distribution of is a Studentâ€™s t-distribution with <span class="math inline">\(n-1\)</span> degrees of freedom.</p>
<p><strong>Explanation of degrees of freedom:</strong> Recall the formula for sample standard deviation is <span class="math inline">\(\sqrt{{\frac{\sum{x-\bar{x}}}{n-1}}}\)</span>. Notice the denominator is <span class="math inline">\(n-1\)</span>. This is the same as the degrees of freedom. This is no accident. The reason the denominator and the degrees of freedom are both comes from how the standard deviation is calculated. First you take each data value and subtract <span class="math inline">\(\bar{x}\)</span>. If you add up all of these new values, you will get 0. This must happen. Since it must happen, the first data values you have â€œfreedom of choiceâ€, but the nth data value, you have no freedom to choose. Hence, you have <span class="math inline">\(n-1\)</span> degrees of freedom. Another way to think about it is that if you five people and five chairs, the first four people have a choice of where they are sitting, but the last person does not. They have no freedom of where to sit. Only <span class="math inline">\(n-1\)</span> people have freedom of choice.</p>
<p>The Studentâ€™s t-distribution is a bell-shape that is more spread out than the normal distribution. There are many t-distributions, one for each different degree of freedom.</p>
<p>(Figure <a href="one-sample-inference.html#fig:tdistribution-graph">7.2</a>) is of the normal distribution and the Studentâ€™s t-distribution for df = 1, df = 3, df=8, df=30.</p>

<div class="figure"><span id="fig:tdistribution-graph"></span>
<img src="Statistics_using_technology_files/figure-html/tdistribution-graph-1.png" alt="Student t distributions with different degrees of freedom and normal curve." width="672" />
<p class="caption">
Figure 7.2: Typical Student t-Distributions
</p>
</div>
<p>As the degrees of freedom increases, the studentâ€™s t-distribution looks
more like the normal distribution.</p>
<p>To find probabilities for the t-distribution, again technology can do this for you. There are many technologies out there that you can use.</p>
<p><strong>Hypothesis Test for One Population Mean (t-Test)</strong></p>
<ol style="list-style-type: decimal">
<li>State the random variable and the parameter in words.</li>
</ol>
<p><em>x</em> = random variable</p>
<p><span class="math inline">\(\mu\)</span> = mean of random variable</p>
<ol start="2" style="list-style-type: decimal">
<li>State the null and alternative hypotheses and the level of
significance</li>
</ol>
<p><span class="math inline">\(H_o:\mu=\mu_o\)</span> , where <span class="math inline">\(\mu_o\)</span> is the known mean</p>
<p><span class="math inline">\(H_a:\mu\ne\mu_o\)</span>, you can also use &lt; or &gt;, but <span class="math inline">\(\ne\)</span> is the more modern one to use.</p>
<p>Also, state your <span class="math inline">\(\alpha\)</span> level here.</p>
<ol start="3" style="list-style-type: decimal">
<li>State and check the assumptions for a hypothesis test</li>
</ol>
<ol style="list-style-type: lower-alpha">
<li><p>A random sample of size <em>n</em> is taken.</p></li>
<li><p>The population of the random variable is normally distributed. The t-test is fairly robust to the condition if the sample size is large. This means that if this condition isnâ€™t met, but your sample size is quite large, then the results of the t-test are valid.</p></li>
<li><p>The population standard deviation, <span class="math inline">\(\sigma\)</span>, is unknown.</p></li>
</ol>
<ol start="4" style="list-style-type: decimal">
<li>Find the sample statistic, test statistic, and p-value</li>
</ol>
<p>On R Studio, the command is</p>
<div class="sourceCode" id="cb317"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb317-1"><a href="one-sample-inference.html#cb317-1"></a><span class="kw">t.test</span>(<span class="op">~</span>variable, <span class="dt">data=</span>data frame, <span class="dt">mu=</span>what Ho says)</span></code></pre></div>
<ol start="5" style="list-style-type: decimal">
<li>Conclusion</li>
</ol>
<p>This is where you write reject or fail to reject <span class="math inline">\(H_o\)</span>. The rule is: if the p-value <span class="math inline">\(&lt;\alpha\)</span> , then reject <span class="math inline">\(H_o\)</span>. If the p-value <span class="math inline">\(\ge \alpha\)</span>, then fail to reject <span class="math inline">\(H_o\)</span></p>
<ol start="6" style="list-style-type: decimal">
<li>Interpretation</li>
</ol>
<p>This is where you interpret in real world terms the conclusion to the test. The conclusion for a hypothesis test is that you either have enough evidence to support <span class="math inline">\(H_a\)</span>, or you do not have enough evidence to support <span class="math inline">\(H_a\)</span>.</p>
<p><strong>How to check the assumptions of t-test:</strong></p>
<p>In order for the t-test to be valid, the assumptions of the test must be true. Whenever you run a t-test, you must make sure the assumptions are true. You need to check them. Here is how you do this:</p>
<ol style="list-style-type: decimal">
<li><p>For the condition that the sample is a random sample, describe how you took the sample. Make sure your sampling technique is random.</p></li>
<li><p>For the condition that population of the random variable is normal, remember the process of assessing normality from chapter 6.</p></li>
</ol>
<p>Note: if the assumptions behind this test are not valid, then the conclusions you make from the test are not valid. If you do not have a random sample, that is your fault. Make sure the sample you take is as random as you can make it following sampling techniques from chapter 1. If the population of the random variable is not normal, then take a larger sample. If you cannot afford to do that, or if it is not logistically possible, then you do different tests called non-parametric tests or you can try resampling. There is an entire course on non-parametric tests, and they will not be discussed in this book.</p>
</div>
<div id="example-test-of-the-mean-using-one-sample-t-test" class="section level3">
<h3><span class="header-section-number">7.3.2</span> Example: Test of the Mean Using One Sample T-test</h3>
<p>A random sample of 50 body mass index (BMI) were taken from the NHANES Data frame The mean BMI of Australians is 27.2 <span class="math inline">\(kg/m^2\)</span>. Is there evidence that Americans have a different BMI from people in Australia. Test at the 5% level.</p>
<p><strong>Table #7.3.2: BMI of Americans</strong></p>
<div class="sourceCode" id="cb318"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb318-1"><a href="one-sample-inference.html#cb318-1"></a>sample_NHANES_<span class="dv">50</span>&lt;-</span>
<span id="cb318-2"><a href="one-sample-inference.html#cb318-2"></a><span class="st">  </span><span class="kw">sample_n</span>(NHANES, <span class="dt">size=</span><span class="dv">50</span>)</span>
<span id="cb318-3"><a href="one-sample-inference.html#cb318-3"></a><span class="kw">head</span>(sample_NHANES_<span class="dv">50</span>)</span></code></pre></div>
<pre><code>## # A tibble: 6 Ã— 76
##      ID SurveyYr Gender   Age AgeDecade AgeMonths Race1  
##   &lt;int&gt; &lt;fct&gt;    &lt;fct&gt;  &lt;int&gt; &lt;fct&gt;         &lt;int&gt; &lt;fct&gt;  
## 1 55594 2009_10  male       1 &quot; 0-9&quot;           12 Mexican
## 2 60959 2009_10  female     6 &quot; 0-9&quot;           78 White  
## 3 59922 2009_10  female    64 &quot; 60-69&quot;        775 White  
## 4 55324 2009_10  male      46 &quot; 40-49&quot;        552 White  
## 5 60215 2009_10  male      80  &lt;NA&gt;            NA White  
## 6 70473 2011_12  female    50 &quot; 50-59&quot;         NA White  
## # â€¦ with 69 more variables: Race3 &lt;fct&gt;, Education &lt;fct&gt;,
## #   MaritalStatus &lt;fct&gt;, HHIncome &lt;fct&gt;, HHIncomeMid &lt;int&gt;,
## #   Poverty &lt;dbl&gt;, HomeRooms &lt;int&gt;, HomeOwn &lt;fct&gt;,
## #   Work &lt;fct&gt;, Weight &lt;dbl&gt;, Length &lt;dbl&gt;, HeadCirc &lt;dbl&gt;,
## #   Height &lt;dbl&gt;, BMI &lt;dbl&gt;, BMICatUnder20yrs &lt;fct&gt;,
## #   BMI_WHO &lt;fct&gt;, Pulse &lt;int&gt;, BPSysAve &lt;int&gt;,
## #   BPDiaAve &lt;int&gt;, BPSys1 &lt;int&gt;, BPDia1 &lt;int&gt;,
## #   BPSys2 &lt;int&gt;, BPDia2 &lt;int&gt;, BPSys3 &lt;int&gt;, BPDia3 &lt;int&gt;,
## #   Testosterone &lt;dbl&gt;, DirectChol &lt;dbl&gt;, TotChol &lt;dbl&gt;,
## #   UrineVol1 &lt;int&gt;, UrineFlow1 &lt;dbl&gt;, UrineVol2 &lt;int&gt;,
## #   UrineFlow2 &lt;dbl&gt;, Diabetes &lt;fct&gt;, DiabetesAge &lt;int&gt;,
## #   HealthGen &lt;fct&gt;, DaysPhysHlthBad &lt;int&gt;,
## #   DaysMentHlthBad &lt;int&gt;, LittleInterest &lt;fct&gt;,
## #   Depressed &lt;fct&gt;, nPregnancies &lt;int&gt;, nBabies &lt;int&gt;,
## #   Age1stBaby &lt;int&gt;, SleepHrsNight &lt;int&gt;,
## #   SleepTrouble &lt;fct&gt;, PhysActive &lt;fct&gt;,
## #   PhysActiveDays &lt;int&gt;, TVHrsDay &lt;fct&gt;, CompHrsDay &lt;fct&gt;,
## #   TVHrsDayChild &lt;int&gt;, CompHrsDayChild &lt;int&gt;,
## #   Alcohol12PlusYr &lt;fct&gt;, AlcoholDay &lt;int&gt;,
## #   AlcoholYear &lt;int&gt;, SmokeNow &lt;fct&gt;, Smoke100 &lt;fct&gt;,
## #   Smoke100n &lt;fct&gt;, SmokeAge &lt;int&gt;, Marijuana &lt;fct&gt;,
## #   AgeFirstMarij &lt;int&gt;, RegularMarij &lt;fct&gt;,
## #   AgeRegMarij &lt;int&gt;, HardDrugs &lt;fct&gt;, SexEver &lt;fct&gt;,
## #   SexAge &lt;int&gt;, SexNumPartnLife &lt;int&gt;,
## #   SexNumPartYear &lt;int&gt;, SameSex &lt;fct&gt;,
## #   SexOrientation &lt;fct&gt;, PregnantNow &lt;fct&gt;</code></pre>
<p><strong>Solution:</strong></p>
<ol style="list-style-type: decimal">
<li>State the random variable and the parameter in words.</li>
</ol>
<p><em>x</em> = BMI of an American</p>
<p><span class="math inline">\(\mu\)</span> = mean BMI of Americans</p>
<ol start="2" style="list-style-type: decimal">
<li>State the null and alternative hypotheses and the level of significance</li>
</ol>
<p><span class="math inline">\(H_o:\mu=27.2\)</span></p>
<p><span class="math inline">\(H_a:\mu\ne 27.2\)</span></p>
<p>level of significance <span class="math inline">\(\alpha=0.05\)</span></p>
<ol start="3" style="list-style-type: decimal">
<li>State and check the assumptions for a hypothesis test</li>
</ol>
<ol style="list-style-type: lower-alpha">
<li><p>A random sample of 50 BMI levels was taken. Check: A random sample was taken from the NHANES data frame using R Studio</p></li>
<li><p>The population of BMI levels is normally distributed. Check:</p></li>
</ol>

<div class="sourceCode" id="cb320"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb320-1"><a href="one-sample-inference.html#cb320-1"></a><span class="kw">gf_density</span>(<span class="op">~</span>BMI, <span class="dt">data=</span>sample_NHANES_<span class="dv">50</span>)</span></code></pre></div>
<div class="figure"><span id="fig:sample-NHANES-50-density"></span>
<img src="Statistics_using_technology_files/figure-html/sample-NHANES-50-density-1.png" alt="Density plot of BMI." width="672" />
<p class="caption">
Figure 7.3: Density Plot of BMI from NHANES sample
</p>
</div>

<div class="sourceCode" id="cb321"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb321-1"><a href="one-sample-inference.html#cb321-1"></a><span class="kw">gf_qq</span>(<span class="op">~</span>BMI, <span class="dt">data=</span>sample_NHANES_<span class="dv">50</span>)</span></code></pre></div>
<div class="figure"><span id="fig:sample-HNANES-50-qq"></span>
<img src="Statistics_using_technology_files/figure-html/sample-HNANES-50-qq-1.png" alt="Normal quantile plot of BMI." width="672" />
<p class="caption">
Figure 7.4: Normal Quantile Plot of BMI from NHANES sample
</p>
</div>
<p>The density plot looks somewhat skewed right and the normal quantile plot looks somewhat linear. However, there doesnâ€™t seem to be strong evidence that the sample comes from a population that is normally distributed. However, since the sample is moderate to large, the t-test is robust to this assumption not being met. So the results of the test are probably valid.</p>
<ol start="4" style="list-style-type: decimal">
<li>Find the sample statistic, test statistic, and p-value</li>
</ol>
<p>On R Studio, the command would be</p>
<div class="sourceCode" id="cb322"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb322-1"><a href="one-sample-inference.html#cb322-1"></a><span class="kw">t.test</span>(<span class="op">~</span>BMI, <span class="dt">data=</span> sample_NHANES_<span class="dv">50</span>, <span class="dt">mu=</span><span class="fl">27.2</span>)</span></code></pre></div>
<pre><code>## 
##  One Sample t-test
## 
## data:  BMI
## t = -0.91146, df = 47, p-value = 0.3667
## alternative hypothesis: true mean is not equal to 27.2
## 95 percent confidence interval:
##  23.97413 28.41420
## sample estimates:
## mean of x 
##  26.19417</code></pre>
<p>The test statistic is the t in the output, the sample statistic is the mean of x in the output, and the p-value is the p-value is the output.</p>
<ol start="5" style="list-style-type: decimal">
<li>Conclusion</li>
</ol>
<p>Since the p-value is not less than 5%, then fail to reject <span class="math inline">\(H_o\)</span>.</p>
<ol start="6" style="list-style-type: decimal">
<li>Interpretation</li>
</ol>
<p>There is not enough evidence to support that Americans have a different BMI from Australians.</p>
<p>Note: this is the same conclusion that was found when using resampling. So the two method could give similar conclusions.</p>
</div>
<div id="example-test-of-the-mean-using-one-sample-t-test-1" class="section level3">
<h3><span class="header-section-number">7.3.3</span> Example: Test of the Mean Using One Sample T-test</h3>
<p>In 2011, the average life expectancy for a woman in Europe was 79.8 years. The data in table #7.3.3 are the life expectancies for all people in European countries ("WHO life expectancy," 2013). Table #7.3.4 filtered the data frame for just males and just year 2000. The year 2000 was randomly chosen as the year to use. Do the data indicate that menâ€™s life expectancy is different from womenâ€™s? Test at the 1% level.</p>
<p><strong>Table #7.3.3: Life Expectancies for European Countries</strong></p>
<div class="sourceCode" id="cb324"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb324-1"><a href="one-sample-inference.html#cb324-1"></a>Expectancy&lt;-<span class="kw">read.csv</span>(</span>
<span id="cb324-2"><a href="one-sample-inference.html#cb324-2"></a>  <span class="st">&quot;https://krkozak.github.io/MAT160/Life_expectancy_Europe.csv&quot;</span>)</span>
<span id="cb324-3"><a href="one-sample-inference.html#cb324-3"></a><span class="kw">head</span>(Expectancy)</span></code></pre></div>
<pre><code>##   year WHO_region country        sex expect
## 1 1990     Europe Albania       Male     67
## 2 1990     Europe Albania     Female     71
## 3 1990     Europe Albania Both sexes     69
## 4 2000     Europe Albania       Male     68
## 5 2000     Europe Albania     Female     73
## 6 2000     Europe Albania Both sexes     71</code></pre>
<p><strong>Table #7.3.4: Life Expectancies of males in European Countries in 2000</strong></p>
<div class="sourceCode" id="cb326"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb326-1"><a href="one-sample-inference.html#cb326-1"></a>Expectancy_male&lt;-</span>
<span id="cb326-2"><a href="one-sample-inference.html#cb326-2"></a><span class="st">  </span>Expectancy<span class="op">%&gt;%</span></span>
<span id="cb326-3"><a href="one-sample-inference.html#cb326-3"></a><span class="st">  </span><span class="kw">filter</span>(sex<span class="op">==</span><span class="st">&quot;Male&quot;</span>, year<span class="op">==</span><span class="st">&quot;2000&quot;</span>)</span>
<span id="cb326-4"><a href="one-sample-inference.html#cb326-4"></a><span class="kw">head</span>(Expectancy_male)</span></code></pre></div>
<pre><code>##   year WHO_region    country  sex expect
## 1 2000     Europe    Albania Male     68
## 2 2000     Europe    Andorra Male     76
## 3 2000     Europe    Armenia Male     68
## 4 2000     Europe    Austria Male     75
## 5 2000     Europe Azerbaijan Male     64
## 6 2000     Europe    Belarus Male     63</code></pre>
<p><strong>Code book for data frame Expectancy</strong></p>
<p><strong>Description</strong>
This data extract has been generated by the Global Health Observatory of the World Health Organization. The data was extracted on 2013-09-19 13:10:20.0.</p>
<p>This data frame contains the following columns:</p>
<p>year: year for life expectancies</p>
<p>WHO_region: World Health Organizations designation for the location of the country</p>
<p>country: country where the epectancies are from</p>
<p>sex: sex of the group that expectancies are calculated for</p>
<p>expect: average life expectancies of the different groups of the different countries.</p>
<p><strong>Source</strong>
<a href="http://apps.who.int/gho/athena/data/download.xsl?format=xml&amp;target=GHO/WHOSIS_000001&amp;profile=excel&amp;filter=COUNTRY" class="uri">http://apps.who.int/gho/athena/data/download.xsl?format=xml&amp;target=GHO/WHOSIS_000001&amp;profile=excel&amp;filter=COUNTRY</a>:<em>;SEX:</em>;REGION:EUR</p>
<p><strong>References</strong>
World Health Organization (WHO).</p>
<p><strong>Solution:</strong></p>
<ol style="list-style-type: decimal">
<li>State the random variable and the parameter in words.</li>
</ol>
<p><em>x</em> = life expectancy for a European man</p>
<p><span class="math inline">\(\mu\)</span> = mean life expectancy for European men</p>
<ol start="2" style="list-style-type: decimal">
<li>State the null and alternative hypotheses and the level of significance</li>
</ol>
<p><span class="math inline">\(H_o:\mu=79.8\)</span></p>
<p><span class="math inline">\(H_a:\mu\ne79.8\)</span></p>
<p><span class="math inline">\(\alpha=0.01\)</span></p>
<ol start="3" style="list-style-type: decimal">
<li>State and check the assumptions for a hypothesis test</li>
</ol>
<ol style="list-style-type: lower-alpha">
<li><p>A random sample of 53 life expectancies of European men in 2000 was taken. Check: The data is actually all of the life expectancies for every country that is considered part of Europe by the World Health Organization in the year 2000. Since the year 2000 was picked at random, then the sample is a random sample.</p></li>
<li><p>The distribution of life expectancies of European men in 2000 is normally distributed. Check:</p></li>
</ol>

<div class="sourceCode" id="cb328"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb328-1"><a href="one-sample-inference.html#cb328-1"></a><span class="kw">gf_density</span>(<span class="op">~</span>expect, <span class="dt">data=</span>Expectancy_male)</span></code></pre></div>
<div class="figure"><span id="fig:expectancy-male-density"></span>
<img src="Statistics_using_technology_files/figure-html/expectancy-male-density-1.png" alt="Density plot of life expectancy of males in Europ in 2000." width="672" />
<p class="caption">
Figure 7.5: Density Plot of Life Expectancies of Males in Europe in 2000
</p>
</div>

<div class="sourceCode" id="cb329"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb329-1"><a href="one-sample-inference.html#cb329-1"></a><span class="kw">gf_qq</span>(<span class="op">~</span>expect, <span class="dt">data=</span>Expectancy_male)</span></code></pre></div>
<div class="figure"><span id="fig:expanctancy-male-qq"></span>
<img src="Statistics_using_technology_files/figure-html/expanctancy-male-qq-1.png" alt="Normal  quantile plot of life expectancy of males." width="672" />
<p class="caption">
Figure 7.6: Normal Quantile Plot of Life Expectancies of Males in Europe in 2000
</p>
</div>
<p>This sample does not appear to come from a population that is normally distributed. This sample is moderate to large, so it is good that the t-test is robust.</p>
<ol start="4" style="list-style-type: decimal">
<li>Find the sample statistic, test statistic, and p-value</li>
</ol>
<p>On R Studio, the command is</p>
<div class="sourceCode" id="cb330"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb330-1"><a href="one-sample-inference.html#cb330-1"></a><span class="kw">t.test</span>(<span class="op">~</span>expect, <span class="dt">data=</span>Expectancy_male, <span class="dt">mu=</span><span class="fl">79.8</span>)</span></code></pre></div>
<pre><code>## 
##  One Sample t-test
## 
## data:  expect
## t = -11.733, df = 52, p-value = 3.145e-16
## alternative hypothesis: true mean is not equal to 79.8
## 95 percent confidence interval:
##  69.11930 72.23919
## sample estimates:
## mean of x 
##  70.67925</code></pre>
<p>Sample statistic is 70.68 years, test statistic is t = -11.733, and p-value <span class="math inline">\(=3.14X10^{-16}\)</span>.</p>
<ol start="5" style="list-style-type: decimal">
<li>Conclusion</li>
</ol>
<p>Since the p-value is less than 1%, then reject <span class="math inline">\(H_o\)</span>.</p>
<ol start="6" style="list-style-type: decimal">
<li>Interpretation</li>
</ol>
<p>There is enough evidence to support that the mean life expectancy for European men is different than the mean life expectancy for European women of 79.8 years.</p>
<p>Note: if you want to conduct a hypothesis test with <span class="math inline">\(H_a:\mu&gt;\mu_o\)</span>, then the R Studio command would be</p>
<div class="sourceCode" id="cb332"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb332-1"><a href="one-sample-inference.html#cb332-1"></a><span class="kw">t.test</span>(<span class="op">~</span>variable, <span class="dt">data=</span>Data Frame, <span class="dt">mu=</span>, <span class="dt">alternative=</span><span class="st">&quot;greater&quot;</span>)</span></code></pre></div>
<p>If you want to conduct a hypothesis test with <span class="math inline">\(H_a:\mu&lt;\mu_o\)</span>, then the R Studio command would be</p>
<div class="sourceCode" id="cb333"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb333-1"><a href="one-sample-inference.html#cb333-1"></a><span class="kw">t.test</span>(<span class="op">~</span>variable, <span class="dt">data=</span>Data Frame, <span class="dt">mu=</span>, <span class="dt">alternative=</span><span class="st">&quot;less&quot;</span>)</span></code></pre></div>
</div>
<div id="homework-18" class="section level3">
<h3><span class="header-section-number">7.3.4</span> Homework</h3>
<p><strong>In each problem show all steps of the hypothesis test. If some of the assumptions are not met, note that the results of the test may not be correct and then continue the process of the hypothesis test.</strong></p>
<ol style="list-style-type: decimal">
<li>The Kyoto Protocol was signed in 1997, and required countries to start reducing their carbon emissions. The protocol became enforceable in February 2005. In 2004, the mean CO2 emission was 4.87 metric tons per capita. Table 7.3.5 contains a random sample of CO2 emissions in 2010 (CO2 emissions (metric tons per capita), 2018). Is there enough evidence to show that the mean CO2 emission is different in 2010 than in 2004? Test at the 1% level.</li>
</ol>
<p><strong>Table #7.3.5: CO2 Emissions (in metric tons per capita) in 2010</strong></p>
<div class="sourceCode" id="cb334"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb334-1"><a href="one-sample-inference.html#cb334-1"></a>Emission &lt;-<span class="st"> </span><span class="kw">read.csv</span>(</span>
<span id="cb334-2"><a href="one-sample-inference.html#cb334-2"></a>  <span class="st">&quot;https://krkozak.github.io/MAT160/CO2_emission.csv&quot;</span>)</span>
<span id="cb334-3"><a href="one-sample-inference.html#cb334-3"></a><span class="kw">head</span>(Emission)</span></code></pre></div>
<pre><code>##       country      y1960      y1961      y1962      y1963
## 1       Aruba         NA         NA         NA         NA
## 2 Afghanistan 0.04605671 0.05358884 0.07372083 0.07416072
## 3      Angola 0.10083534 0.08220380 0.21053148 0.20273730
## 4     Albania 1.25819493 1.37418605 1.43995596 1.18168114
## 5     Andorra         NA         NA         NA         NA
## 6  Arab World 0.64573587 0.68746538 0.76357363 0.87823769
##        y1964     y1965     y1966     y1967     y1968
## 1         NA        NA        NA        NA        NA
## 2 0.08617361 0.1012849 0.1073989 0.1234095 0.1151425
## 3 0.21356035 0.2058909 0.2689414 0.1721017 0.2897181
## 4 1.11174196 1.1660990 1.3330555 1.3637463 1.5195513
## 5         NA        NA        NA        NA        NA
## 6 1.00305335 1.1705403 1.2781736 1.3374436 1.5522420
##        y1969     y1970     y1971     y1972     y1973
## 1         NA        NA        NA        NA        NA
## 2 0.08650986 0.1496515 0.1652083 0.1299956 0.1353666
## 3 0.48023402 0.6082236 0.5645482 0.7212460 0.7512399
## 4 1.55896757 1.7532399 1.9894979 2.5159144 2.3038974
## 5         NA        NA        NA        NA        NA
## 6 1.79866893 1.8103078 2.0037220 2.1208746 2.4095329
##       y1974     y1975     y1976     y1977     y1978
## 1        NA        NA        NA        NA        NA
## 2 0.1545032 0.1676124 0.1535579 0.1815222 0.1618942
## 3 0.7207764 0.6285689 0.4513535 0.4692212 0.6947369
## 4 1.8490067 1.9106336 2.0135846 2.2758764 2.5306250
## 5        NA        NA        NA        NA        NA
## 6 2.2858907 2.1967827 2.5843424 2.6487624 2.7623331
##       y1979     y1980     y1981     y1982     y1983
## 1        NA        NA        NA        NA        NA
## 2 0.1670664 0.1317829 0.1506147 0.1631039 0.2012243
## 3 0.6830629 0.6409664 0.6111351 0.5193546 0.5513486
## 4 2.8982085 1.9350583 2.6930239 2.6248568 2.6832399
## 5        NA        NA        NA        NA        NA
## 6 2.8636143 3.0928915 2.9302350 2.7231544 2.8165670
##       y1984     y1985     y1986     y1987      y1988
## 1        NA        NA 2.8683194 7.2351980 10.0261792
## 2 0.2319613 0.2939569 0.2677719 0.2692296  0.2468233
## 3 0.5209829 0.4719028 0.4516189 0.5440851  0.4635083
## 4 2.6942914 2.6580154 2.6653562 2.4140608  2.3315985
## 5        NA        NA        NA        NA         NA
## 6 2.9813539 3.0618504 3.2844996 3.1978064  3.2950428
##        y1989      y1990      y1991       y1992       y1993
## 1 10.6347326 26.3745032 26.0461298 21.44255880 22.00078616
## 2  0.2338822  0.2106434  0.1833636  0.09619658  0.08508711
## 3  0.4372955  0.4317436  0.4155308  0.41052293  0.44172110
## 4  2.7832431  1.6781067  1.3122126  0.77472491  0.72379029
## 5         NA  7.4673357  7.1824566  6.91205339  6.73605485
## 6  3.2566742  3.0169588  3.2366449  3.41548491  3.66944563
##         y1994       y1995       y1996       y1997
## 1 21.03624511 20.77193616 20.31835337 20.42681771
## 2  0.07580649  0.06863986  0.06243461  0.05664234
## 3  0.28811907  0.78703255  0.72623346  0.49636125
## 4  0.60020371  0.65453713  0.63662531  0.49036506
## 5  6.49420042  6.66205168  7.06507147  7.23971272
## 6  3.67435821  3.42400952  3.32830368  3.14553220
##         y1998       y1999       y2000       y2001
## 1 20.58766915 20.31156677 26.19487524 25.93402441
## 2  0.05276322  0.04072254  0.03723478  0.03784614
## 3  0.47581516  0.57708291  0.58196150  0.57431605
## 4  0.56027144  0.96016441  0.97817468  1.05330418
## 5  7.66078389  7.97545440  8.01928429  7.78695000
## 6  3.34996719  3.32834106  3.70385708  3.60795615
##         y2002       y2003       y2004       y2005
## 1 25.67116178 26.42045209 26.51729342 27.20070778
## 2  0.04737732  0.05048134  0.03841004  0.05174397
## 3  0.72295888  0.50022540  1.00187812  0.98573636
## 4  1.22954071  1.41269720  1.37621273  1.41249821
## 5  7.59061514  7.31576071  7.35862494  7.29987194
## 6  3.60461275  3.79646741  4.06856241  4.18567731
##         y2006       y2007      y2008      y2009      y2010
## 1 26.94772597 27.89502282 26.2295527 25.9153221 24.6705289
## 2  0.06242753  0.08389281  0.1517209  0.2383985  0.2899876
## 3  1.10501903  1.20313400  1.1850005  1.2344251  1.2440915
## 4  1.30257637  1.32233486  1.4843111  1.4956002  1.5785736
## 5  6.74605213  6.51938706  6.4278100  6.1215799  6.1225947
## 6  4.28571918  4.11714755  4.4089483  4.5620151  4.6368134
##        y2011      y2012    y2013     y2014 y2015 y2016
## 1 24.5075162 13.1577223 8.353561 8.4100642    NA    NA
## 2  0.4064242  0.3451488 0.310341 0.2939464    NA    NA
## 3  1.2526808  1.3302186 1.253776 1.2903068    NA    NA
## 4  1.8037147  1.6929083 1.749211 1.9787633    NA    NA
## 5  5.8674102  5.9168840 5.901775 5.8329062    NA    NA
## 6  4.5594617  4.8377796 4.674925 4.8869875    NA    NA
##   y2017 y2018
## 1    NA    NA
## 2    NA    NA
## 3    NA    NA
## 4    NA    NA
## 5    NA    NA
## 6    NA    NA</code></pre>
<p><strong>Code book for data frame Emission</strong></p>
<p><strong>Description</strong>
Carbon dioxide emissions are those stemming from the burning of fossil fuels and the manufacture of cement. They include carbon dioxide produced during consumption of solid, liquid, and gas fuels and gas flaring.</p>
<p>This data frame contains the following columns:</p>
<p>country: country around the world</p>
<p>y1960-y2018: weighted averages of CO2 emission for the years 1960 through 2018 in metric tons per capita</p>
<p><strong>Source</strong>
CO2 emissions (metric tons per capita). (n.d.). Retrieved July 18, 2019, from <a href="https://data.worldbank.org/indicator/EN.ATM.CO2E.PC" class="uri">https://data.worldbank.org/indicator/EN.ATM.CO2E.PC</a></p>
<p><strong>References</strong>
Carbon Dioxide Information Analysis Center, Environmental Sciences Division, Oak Ridge National Laboratory, Tennessee, United States.</p>
<ol start="2" style="list-style-type: decimal">
<li>The amount of sugar in a Krispy Kream glazed donut is 10 g. Many people feel that cereal is a healthier alternative for children over glazed donuts. Table #7.3.6 contains the amount of sugar in a sample of cereal that is geared towards children (breakfast cereal, 2019). Is there enough evidence to show that the mean amount of sugar in childrenâ€™s cereal is different than in a glazed donut? Test at the 5% level.</li>
</ol>
<p><strong>Table #7.3.6: Nutrition Amounts in Cereal</strong></p>
<div class="sourceCode" id="cb336"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb336-1"><a href="one-sample-inference.html#cb336-1"></a>Sugar &lt;-<span class="st"> </span><span class="kw">read.csv</span>(</span>
<span id="cb336-2"><a href="one-sample-inference.html#cb336-2"></a>  <span class="st">&quot;https://krkozak.github.io/MAT160/cereal.csv&quot;</span>)</span>
<span id="cb336-3"><a href="one-sample-inference.html#cb336-3"></a><span class="kw">head</span>(Sugar)</span></code></pre></div>
<pre><code>##                        name           manf   age type
## 1                 100%_Bran        Nabisco adult cold
## 2         100%_Natural_Bran    Quaker_Oats adult cold
## 3                  All-Bran       Kelloggs adult cold
## 4 All-Bran_with_Extra_Fiber       Kelloggs adult cold
## 5            Almond_Delight Ralston_Purina adult cold
## 6   Apple_Cinnamon_Cheerios  General_Mills child cold
##   colories protein fat sodium fiber carb sugar shelf
## 1       70       4   1    130  10.0  5.0     6     3
## 2      120       3   5     15   2.0  8.0     8     3
## 3       70       4   1    260   9.0  7.0     5     3
## 4       50       4   0    140  14.0  8.0     0     3
## 5      110       2   2    200   1.0 14.0     8     3
## 6      110       2   2    180   1.5 10.5    10     1
##   potassium vit weight serving
## 1       280  25      1    0.33
## 2       135   0      1   -1.00
## 3       320  25      1    0.33
## 4       330  25      1    0.50
## 5        -1  25      1    0.75
## 6        70  25      1    0.75</code></pre>
<p><strong>Code book for data frame Sugar</strong></p>
<p><strong>Description</strong>
Nutritional information about cereals.</p>
<p>This data frame contains the following columns:</p>
<p>name: the cereal brand</p>
<p>manf: manufacturer</p>
<p>age: whether the cereal is geared towards children or adults</p>
<p>type: whether the cereal is considered a hot or cold cereal</p>
<p>calories: the number of calories in the cereal (number)</p>
<p>protein: the amount of protein in a serving of the cereal (g)</p>
<p>fat: the amount of fat a serving of the cereal (g)</p>
<p>sodium: the amount of sodium in a serving of the cereal (mg)</p>
<p>fiber: the amount of fiber in a serving of the cereal (g)</p>
<p>carb: the amount of complex carbohydrates in a serving of the cereal (g)</p>
<p>sugars: the amount of sugar in a serving of the cereal (g)</p>
<p>display shelf: what shelf the cereal is on counting from the floor</p>
<p>potassium: the amount of potassium in a serving of the cereal (mg)</p>
<p>vit: the amount of vitamins and minerals in a serving of the cereal (0, 25, or 100)</p>
<p>weight: weight in ounces of one serving</p>
<p>serving: cups per serving</p>
<p><strong>Source</strong>
(n.d.). Retrieved July 18, 2019, from <a href="https://www.idvbook.com/teaching-aid/data-sets/the-breakfast-cereal-data-set/" class="uri">https://www.idvbook.com/teaching-aid/data-sets/the-breakfast-cereal-data-set/</a>
The Best Kidsâ€™ Cereal. (n.d.). Retrieved July 18, 2019, from <a href="https://www.ranker.com/list/best-kids-cereal/ranker-food" class="uri">https://www.ranker.com/list/best-kids-cereal/ranker-food</a></p>
<p><strong>References</strong>
Interactive Data Visualization
Foundations, Techniques, Applications (Matthew Ward | Georges Grinstein | Daniel Keim)</p>
<p>A new data frame will need to be created of just cereal for children. To create that use the following command in R Studio</p>
<p><strong>Table #7.3.7: Nutrition Amounts in Childrenâ€™s Cereal</strong></p>
<div class="sourceCode" id="cb338"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb338-1"><a href="one-sample-inference.html#cb338-1"></a>Sugar_children&lt;-</span>
<span id="cb338-2"><a href="one-sample-inference.html#cb338-2"></a>Sugar<span class="op">%&gt;%</span></span>
<span id="cb338-3"><a href="one-sample-inference.html#cb338-3"></a><span class="st">  </span><span class="kw">filter</span>(age<span class="op">==</span><span class="st">&quot;child&quot;</span>)</span>
<span id="cb338-4"><a href="one-sample-inference.html#cb338-4"></a><span class="kw">head</span>(Sugar_children)</span></code></pre></div>
<pre><code>##                      name           manf   age type
## 1 Apple_Cinnamon_Cheerios  General_Mills child cold
## 2             Apple_Jacks       Kelloggs child cold
## 3               Bran_Chex Ralston_Purina child cold
## 4            Cap&#39;n&#39;Crunch    Quaker_Oats child cold
## 5                Cheerios  General_Mills child cold
## 6   Cinnamon_Toast_Crunch  General_Mills child cold
##   colories protein fat sodium fiber carb sugar shelf
## 1      110       2   2    180   1.5 10.5    10     1
## 2      110       2   0    125   1.0 11.0    14     2
## 3       90       2   1    200   4.0 15.0     6     1
## 4      120       1   2    220   0.0 12.0    12     2
## 5      110       6   2    290   2.0 17.0     1     1
## 6      120       1   3    210   0.0 13.0     9     2
##   potassium vit weight serving
## 1        70  25      1    0.75
## 2        30  25      1    1.00
## 3       125  25      1    0.67
## 4        35  25      1    0.75
## 5       105  25      1    1.25
## 6        45  25      1    0.75</code></pre>
<ol start="3" style="list-style-type: decimal">
<li>The FDA regulates that fish that is consumed is allowed to contain 1.0 mg/kg of mercury. In Florida, bass fish were collected in 53 different lakes to measure the health of the lakes. The data frame of measurements from Florida lakes is in table #7.3.8 (NISER 081107 ID Data, 2019). Do the data provide enough evidence to show that the fish in Florida lakes has different amounts of mercury than the allowable amount? Test at the 10% level.</li>
</ol>
<p><strong>Table #7.3.8: Health of Florida lake Fish</strong></p>
<div class="sourceCode" id="cb340"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb340-1"><a href="one-sample-inference.html#cb340-1"></a>Mercury&lt;-<span class="st"> </span><span class="kw">read.csv</span>(</span>
<span id="cb340-2"><a href="one-sample-inference.html#cb340-2"></a>  <span class="st">&quot;https://krkozak.github.io/MAT160/mercury.csv&quot;</span>)</span>
<span id="cb340-3"><a href="one-sample-inference.html#cb340-3"></a><span class="kw">head</span>(Mercury)</span></code></pre></div>
<pre><code>##   ID          lake alkalinity  ph calcium chlorophyll
## 1  1     Alligator        5.9 6.1     3.0         0.7
## 2  2         Annie        3.5 5.1     1.9         3.2
## 3  3        Apopka      116.0 9.1    44.1       128.3
## 4  4  Blue_Cypress       39.4 6.9    16.4         3.5
## 5  5         Brick        2.5 4.6     2.9         1.8
## 6  6        Bryant       19.6 7.3     4.5        44.1
##   mercury no.samples  min  max X3_yr_standmercury age_data
## 1    1.23          5 0.85 1.43               1.53        1
## 2    1.33          7 0.92 1.90               1.33        0
## 3    0.04          6 0.04 0.06               0.04        0
## 4    0.44         12 0.13 0.84               0.44        0
## 5    1.20         12 0.69 1.50               1.33        1
## 6    0.27         14 0.04 0.48               0.25        1</code></pre>
<p><strong>Code book for data frame Mercury</strong></p>
<p><strong>Description</strong>
Largemouth bass were studied in 53 different Florida lakes to examine the factors that influence the level of mercury contamination. Water samples were collected from the surface of the middle of each lake in August 1990 and then again in March 1991. The pH level, the amount of chlorophyll, calcium, and alkalinity were measured in each sample. The average of the August and March values were used in the analysis. Next, a sample of fish was taken from each lake with sample sizes ranging from 4 to 44 fish. The age of each fish and mercury concentration in the muscle tissue was measured. (Note: Since fish absorb mercury over time, older fish will tend to have higher concentrations). Thus, to make a fair comparison of the fish in different lakes, the investigators used a regression estimate of the expected mercury concentration in a three year old fish as the standardized value for each lake. Finally, in 10 of the 53 lakes, the age of the individual fish could not be determined and the average mercury concentration of the sampled fish was used instead of the standardized value. ( Reference: Lange, Royals, &amp; Connor. (1993))</p>
<p>This data frame contains the following columns:</p>
<p>ID: ID number</p>
<p>Lake: Name of lake</p>
<p>alkalinity: Alkalinity (mg/L as Calcium Carbonate)</p>
<p>pH: pH</p>
<p>calcium: calcium (mg/l)</p>
<p>chlorophyll: chlorophyll (mg/l)</p>
<p>mercury: Average mercury concentration (parts per million) in the muscle tissue of the fish sampled from that lake</p>
<p>no.samples: How many fish were sampled from the lake</p>
<p>min: Minimum mercury concentration among the sampled fish</p>
<p>max: Maximum mercury concentration among the sampled fish</p>
<p>X3_yr_Standard_mercury: Regression estimate of the mercury concentration in a 3 year old fish from the lake (or = Avg Mercury when age data was not available)</p>
<p>age_data: Indicator of the availability of age data on fish sampled</p>
<p><strong>Source</strong>
Lange TL, Royals HE, Connor LL (1993) Influence of water chemistry on mercury concentration in largemouth bass from Florida lakes. Trans Am Fish Soc 122:74-84.
Michael K. Saiki, Darell G. Slotton, Thomas W. May, Shaun M. Ayers, and Charles N. Alpers (2000) Summary of Total Mercury Concentrations in Fillets of Selected Sport Fishes Collected during 2000â€“2003 from Lake Natoma, Sacramento County, California (Raw data is included in appendix), U.S. Geological Survey Data Series 103, 1-21.
NISER 081107 ID Data. (n.d.). Retrieved July 18, 2019, from <a href="http://wiki.stat.ucla.edu/socr/index.php/NISER_081107_ID_Data" class="uri">http://wiki.stat.ucla.edu/socr/index.php/NISER_081107_ID_Data</a></p>
<p><strong>References</strong>
NISER 081107 ID Data</p>
<ol start="4" style="list-style-type: decimal">
<li>The data frame Pulse (Table 7.3.9) contains various variables about a person including their pulse rates before the subject exercised and after the subject ran in place for one minute. The mean pulse rate after running for 1 minute of females who do not drink is 97 beats per minute. Do the data show that the mean pulse rate of females who do drink alcohol is higher than the mean pulse rate of females who do not drink? Test at the 5% level.</li>
</ol>
<p><strong>Table #7.3.9: Pulse Rates Pulse Rates of people Before and After Exercise</strong></p>
<div class="sourceCode" id="cb342"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb342-1"><a href="one-sample-inference.html#cb342-1"></a>Pulse&lt;-<span class="kw">read.csv</span>(</span>
<span id="cb342-2"><a href="one-sample-inference.html#cb342-2"></a>  <span class="st">&quot;https://krkozak.github.io/MAT160/pulse.csv&quot;</span>)</span>
<span id="cb342-3"><a href="one-sample-inference.html#cb342-3"></a><span class="kw">head</span>(Pulse)</span></code></pre></div>
<pre><code>##   height weight age gender smokes alcohol exercise ran
## 1    170     68  22   male    yes     yes moderate sat
## 2    182     75  26   male    yes     yes moderate sat
## 3    180     85  19   male    yes     yes moderate ran
## 4    182     85  20   male    yes     yes      low sat
## 5    167     70  22   male    yes     yes      low sat
## 6    178     86  21   male    yes     yes      low sat
##   pulse_before pulse_after year
## 1           70          71   93
## 2           80          76   93
## 3           68         125   95
## 4           70          68   95
## 5           92          84   96
## 6           76          80   98</code></pre>
<p><strong>Code book for data frame Pulse</strong>, see homework problem 3.2.5 in section 3.2</p>
<p>Create a data frame that contains only females who drink alcohol. Then test the pulse after for woman who do drink alcohol to the known value for females who do not drink alcohol. To create a new data frame with just females who drink alcohol use the following command, where the new name is Females:</p>
<p><strong>Table #7.3.10: Pulse Rates Pulse Rates of people Before and After Exercise</strong></p>
<div class="sourceCode" id="cb344"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb344-1"><a href="one-sample-inference.html#cb344-1"></a>Females&lt;-</span>
<span id="cb344-2"><a href="one-sample-inference.html#cb344-2"></a>Pulse<span class="op">%&gt;%</span></span>
<span id="cb344-3"><a href="one-sample-inference.html#cb344-3"></a><span class="st">  </span><span class="kw">filter</span>(gender<span class="op">==</span><span class="st">&quot;female&quot;</span>, alcohol<span class="op">==</span><span class="st">&quot;yes&quot;</span>)</span>
<span id="cb344-4"><a href="one-sample-inference.html#cb344-4"></a><span class="kw">head</span>(Females)</span></code></pre></div>
<pre><code>##   height weight age gender smokes alcohol exercise ran
## 1    165     60  19 female    yes     yes      low ran
## 2    163     47  23 female    yes     yes      low ran
## 3    173     57  18 female     no     yes moderate sat
## 4    179     58  19 female     no     yes moderate ran
## 5    167     62  18 female     no     yes     high ran
## 6    173     64  18 female     no     yes      low sat
##   pulse_before pulse_after year
## 1           88         120   98
## 2           71         125   98
## 3           86          88   93
## 4           82         150   93
## 5           96         176   93
## 6           90          88   93</code></pre>
<ol start="5" style="list-style-type: decimal">
<li>The economic dynamism is an index of productive growth in dollars. Economic data for many countries are in table #7.3.11 (SOCR Data 2008 World CountriesRankings, 2019). Countries that are considered high-income have a mean economic dynamism of 60.29.</li>
</ol>
<p><strong>Table #7.3.11: Economic Data for Countries</strong></p>
<div class="sourceCode" id="cb346"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb346-1"><a href="one-sample-inference.html#cb346-1"></a>Economics &lt;-<span class="st"> </span><span class="kw">read.csv</span>(</span>
<span id="cb346-2"><a href="one-sample-inference.html#cb346-2"></a>  <span class="st">&quot;https://krkozak.github.io/MAT160/Economics_country.csv&quot;</span>)</span>
<span id="cb346-3"><a href="one-sample-inference.html#cb346-3"></a><span class="kw">head</span>(Economics)</span></code></pre></div>
<pre><code>##   Id incGroup key       name popGroup          region key2
## 1  0      Low  al    Albania    Small Southern_Europe popS
## 2  1   Middle  dz    Algeria   Medium    North_Africa popM
## 3  2   Middle  ar  Argentina   Medium   South_America popM
## 4  3     High  au  Australia   Medium       Australia popM
## 5  4     High  at    Austria    Small  Central_Europe popS
## 6  5      Low  az Azerbaijan    Small    central_Asia popS
##        ED     Edu      HI     QOL      PE OA Relig
## 1 34.0862 81.0164 71.0244 67.9240 58.6742 57    39
## 2 25.8057 74.8027 66.1951 60.9347 32.6054 85    95
## 3 37.4511 69.8825 78.2683 68.1559 68.6647 46    66
## 4 71.4888 91.4802 95.1707 90.5729 90.9629  4    65
## 5 53.9431 90.4578 90.3415 87.5630 91.2073 18    20
## 6 53.6457 68.9880 58.9512 68.9572 40.0390 69    50</code></pre>
<p><strong>Code book for data frame Economics</strong></p>
<p><strong>Description</strong>
These data represent commonly accepted measures for raking Countries on variety of factors which affect the countryâ€™s internal and external international perception of the countryâ€™s rank relative the to rest of the World.</p>
<p>This data frame contains the following columns:</p>
<p>id: Unique country identifier</p>
<p>incGroup: Income group: Low: GNI per capita &lt; $3,946, Middle: $3,946 &lt; GNI per capita &lt; $12,195, High: GNI per capita &gt; $12,196</p>
<p>key: unique 2-letter country code</p>
<p>name: Country Name</p>
<p>popGroup: Population Group: Small: Population &lt; 20 million, Medium: 20 million &lt; Population &lt; 50 million, Large: Population &gt; 50 million</p>
<p>region: Relative geographic position of the Country</p>
<p>key2: Country Group Classification Label: world: All countries, g7: G7, g20: G20, latin: Latin America &amp; Caribbean, eu: European Union, centasia: Europe &amp; Central Asia, pacasia: East Asia &amp; Pacific, asean: Asean, sasia: South Asia, mideast: Middle East &amp; North Africa, africa: Sub-Saharan Africa, bric: Brazil, Russia, India and China (BRIC)</p>
<p>ED: Economic Dynamism: Index of Productive growth in dollars (GDP/capita at PPP, Avg of GDP/capita growth rate over last ten years, GDP/capita growth rate over next ten years, Economic Dynamism: Manufacturing percent of GDP, Services percent of GDP percent (100=best, 0=worst).</p>
<p>Edu: Education/Literacy Rate (percent of population able to read and write at a specified age)</p>
<p>HI: Health Index: The average number of years a person lives in full health, taking into account years lived in less than full health</p>
<p>QOL: Quality of Life: Population percent living on &lt; $2/day</p>
<p>PE: Political Environment: Freedom house rating of political participation (qualitative assessment of voter participation/turn-out for national elections, citizens engagement with politics)</p>
<p>OA: Overall country ranking taking all measures into account.</p>
<p>Relig: Religiosity of the Country as a percent (%) of the population.</p>
<p><strong>Source</strong>
SOCR Data 2008 World CountriesRankings. (n.d.). Retrieved July 19, 2019, from <a href="http://wiki.stat.ucla.edu/socr/index.php/SOCR_Data_2008_World_CountriesRankings#SOCR_Data_-_Ranking_of_the_top_100_Countries_based_on_Political.2C_Economic.2C_Health.2C_and_Quality-of-Life_Factors" class="uri">http://wiki.stat.ucla.edu/socr/index.php/SOCR_Data_2008_World_CountriesRankings#SOCR_Data_-_Ranking_of_the_top_100_Countries_based_on_Political.2C_Economic.2C_Health.2C_and_Quality-of-Life_Factors</a></p>
<p><strong>References</strong>
SOCR Data 2008 World CountriesRankings, Amazon Web-Services Worldâ€™s Best Countries.</p>
<p>Create a data frame that contains only middle income countries. Do the data show that the mean economic dynamism of middle-income countries is less than the mean for high-income countries? Test at the 5% level. To create a new data frame with just middle income countries use the following command, where the new name is Middle_economics:</p>
<p><strong>Table #7.3.12: Economic Data for Middle income Countries</strong></p>
<div class="sourceCode" id="cb348"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb348-1"><a href="one-sample-inference.html#cb348-1"></a>Middle_economics&lt;-</span>
<span id="cb348-2"><a href="one-sample-inference.html#cb348-2"></a>Economics<span class="op">%&gt;%</span></span>
<span id="cb348-3"><a href="one-sample-inference.html#cb348-3"></a><span class="st">  </span><span class="kw">filter</span>(incGroup<span class="op">==</span><span class="st">&quot;Middle&quot;</span>)</span>
<span id="cb348-4"><a href="one-sample-inference.html#cb348-4"></a><span class="kw">head</span>(Middle_economics)</span></code></pre></div>
<pre><code>##   Id incGroup key      name popGroup          region key2
## 1  1   Middle  dz   Algeria   Medium    North_Africa popM
## 2  2   Middle  ar Argentina   Medium   South_America popM
## 3  7   Middle  by   Belarus    Small    central_Asia popS
## 4 10   Middle  bw  Botswana    Small          Africa popS
## 5 11   Middle  br    Brazil    Large   South_America popL
## 6 12   Middle  bg  Bulgaria    Small Southern_Europe popS
##        ED     Edu      HI     QOL      PE OA Relig
## 1 25.8057 74.8027 66.1951 60.9347 32.6054 85    95
## 2 37.4511 69.8825 78.2683 68.1559 68.6647 46    66
## 3 51.9150 86.6155 66.1951 74.1467 34.0501 56    34
## 4 43.6952 73.4608 34.8049 50.0875 72.6833 80    80
## 5 47.8506 71.3735 71.0244 62.4238 67.4131 48    87
## 6 43.7178 82.2277 75.8537 73.1197 73.1686 38    50</code></pre>
<ol start="6" style="list-style-type: decimal">
<li>In 1999, the average percentage of women who received prenatal care per country is 80.1%. Table #7.3.13 contains the percentage of woman receiving prenatal care in a sample of countries over several years. (births per woman), 2019). Do the data show that the average percentage of women receiving prenatal care in 2009 (p2009) is different than in 1999? Test at the 5% level.</li>
</ol>
<p><strong>Table #7.3.13: Data of Prenatal Care versus Health Expenditure</strong></p>
<div class="sourceCode" id="cb350"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb350-1"><a href="one-sample-inference.html#cb350-1"></a>Fert_prenatal&lt;-<span class="kw">read.csv</span>(</span>
<span id="cb350-2"><a href="one-sample-inference.html#cb350-2"></a>  <span class="st">&quot;https://krkozak.github.io/MAT160/fertility_prenatal.csv&quot;</span>)</span>
<span id="cb350-3"><a href="one-sample-inference.html#cb350-3"></a><span class="kw">head</span>(Fert_prenatal)</span></code></pre></div>
<pre><code>##    Country.Name Country.Code                    Region
## 1        Angola          AGO        Sub-Saharan Africa
## 2       Armenia          ARM     Europe &amp; Central Asia
## 3        Belize          BLZ Latin America &amp; Caribbean
## 4 Cote d&#39;Ivoire          CIV        Sub-Saharan Africa
## 5      Ethiopia          ETH        Sub-Saharan Africa
## 6        Guinea          GIN        Sub-Saharan Africa
##           IncomeGroup f1960 f1961 f1962 f1963 f1964 f1965
## 1 Lower middle income 7.478 7.524 7.563 7.592 7.611 7.619
## 2 Upper middle income 4.786 4.670 4.521 4.345 4.150 3.950
## 3 Upper middle income 6.500 6.480 6.460 6.440 6.420 6.400
## 4 Lower middle income 7.691 7.720 7.750 7.781 7.811 7.841
## 5          Low income 6.880 6.877 6.875 6.872 6.867 6.864
## 6          Low income 6.114 6.127 6.138 6.147 6.154 6.160
##   f1966 f1967 f1968 f1969 f1970 f1971 f1972 f1973 f1974
## 1 7.618 7.613 7.608 7.604 7.601 7.603 7.606 7.611 7.614
## 2 3.758 3.582 3.429 3.302 3.199 3.114 3.035 2.956 2.875
## 3 6.379 6.358 6.337 6.316 6.299 6.288 6.284 6.285 6.287
## 4 7.868 7.893 7.912 7.927 7.936 7.941 7.942 7.939 7.929
## 5 6.867 6.880 6.903 6.937 6.978 7.020 7.060 7.094 7.121
## 6 6.168 6.177 6.189 6.205 6.225 6.249 6.277 6.306 6.337
##   f1975 f1976 f1977 f1978 f1979 f1980 f1981 f1982 f1983
## 1 7.615 7.609 7.594 7.571 7.540 7.504 7.469 7.438 7.413
## 2 2.792 2.712 2.641 2.582 2.538 2.510 2.499 2.503 2.517
## 3 6.278 6.250 6.195 6.109 5.992 5.849 5.684 5.510 5.336
## 4 7.910 7.877 7.828 7.763 7.682 7.590 7.488 7.383 7.278
## 5 7.143 7.167 7.195 7.230 7.271 7.316 7.360 7.397 7.424
## 6 6.369 6.402 6.436 6.468 6.500 6.529 6.557 6.581 6.602
##   f1984 f1985 f1986 f1987 f1988 f1989 f1990 f1991 f1992
## 1 7.394 7.380 7.366 7.349 7.324 7.291 7.247 7.193 7.130
## 2 2.538 2.559 2.578 2.591 2.592 2.578 2.544 2.484 2.400
## 3 5.170 5.019 4.886 4.771 4.671 4.584 4.508 4.436 4.363
## 4 7.176 7.078 6.984 6.892 6.801 6.710 6.622 6.536 6.454
## 5 7.437 7.435 7.418 7.387 7.347 7.298 7.246 7.193 7.143
## 6 6.619 6.631 6.637 6.637 6.631 6.618 6.598 6.570 6.535
##   f1993 f1994 f1995 f1996 f1997 f1998 f1999 f2000 f2001
## 1 7.063 6.992 6.922 6.854 6.791 6.734 6.683 6.639 6.602
## 2 2.297 2.179 2.056 1.938 1.832 1.747 1.685 1.648 1.635
## 3 4.286 4.201 4.109 4.010 3.908 3.805 3.703 3.600 3.496
## 4 6.374 6.298 6.224 6.152 6.079 6.006 5.932 5.859 5.787
## 5 7.094 7.046 6.995 6.935 6.861 6.769 6.659 6.529 6.380
## 6 6.493 6.444 6.391 6.334 6.273 6.211 6.147 6.082 6.015
##   f2002 f2003 f2004 f2005 f2006 f2007 f2008 f2009 f2010
## 1 6.568 6.536 6.502 6.465 6.420 6.368 6.307 6.238 6.162
## 2 1.637 1.648 1.665 1.681 1.694 1.702 1.706 1.703 1.693
## 3 3.390 3.282 3.175 3.072 2.977 2.893 2.821 2.762 2.715
## 4 5.717 5.651 5.589 5.531 5.476 5.423 5.372 5.321 5.269
## 5 6.216 6.044 5.867 5.690 5.519 5.355 5.201 5.057 4.924
## 6 5.947 5.877 5.804 5.729 5.653 5.575 5.496 5.417 5.336
##   f2011 f2012 f2013 f2014 f2015 f2016 f2017 p1986 p1987
## 1 6.082 6.000 5.920 5.841 5.766 5.694 5.623    NA    NA
## 2 1.680 1.664 1.648 1.634 1.622 1.612 1.604    NA    NA
## 3 2.676 2.642 2.610 2.578 2.544 2.510 2.475    NA    NA
## 4 5.216 5.160 5.101 5.039 4.976 4.911 4.846    NA    NA
## 5 4.798 4.677 4.556 4.437 4.317 4.198 4.081    NA    NA
## 6 5.256 5.175 5.094 5.014 4.934 4.855 4.777    NA    NA
##   p1988 p1989 p1990 p1991 p1992 p1993 p1994 p1995 p1996
## 1    NA    NA    NA    NA    NA    NA    NA    NA    NA
## 2    NA    NA    NA    NA    NA    NA    NA    NA    NA
## 3    NA    NA    NA    96    NA    NA    NA    NA    NA
## 4    NA    NA    NA    NA    NA    NA  83.2    NA    NA
## 5    NA    NA    NA    NA    NA    NA    NA    NA    NA
## 6    NA    NA    NA    NA  57.6    NA    NA    NA    NA
##   p1997 p1998 p1999 p2000 p2001 p2002 p2003 p2004 p2005
## 1    NA    NA    NA    NA  65.6    NA    NA    NA    NA
## 2    82    NA    NA  92.4    NA    NA    NA    NA  93.0
## 3    NA    98  95.9 100.0    NA    98    NA    NA  94.0
## 4    NA    NA  84.3  87.6    NA    NA    NA    NA  87.3
## 5    NA    NA    NA  26.7    NA    NA    NA    NA  27.6
## 6    NA    NA  70.7    NA    NA    NA  84.3    NA  82.2
##   p2006 p2007 p2008 p2009 p2010 p2011 p2012 p2013 p2014
## 1    NA  79.8    NA    NA    NA    NA    NA    NA    NA
## 2    NA    NA    NA    NA  99.1    NA    NA    NA    NA
## 3  94.0  99.2    NA    NA    NA  96.2    NA    NA    NA
## 4  84.8    NA    NA    NA    NA    NA  90.6    NA    NA
## 5    NA    NA    NA    NA    NA  33.9    NA    NA  41.2
## 6    NA  88.4    NA    NA    NA    NA  85.2    NA    NA
##   p2015 p2016 p2017 p2018    e2000    e2001    e2002
## 1    NA  81.6    NA    NA 2.334435 5.483824 4.072288
## 2    NA  99.6    NA    NA 6.505224 6.536262 5.690812
## 3  97.2  97.2    NA    NA 3.942030 4.228792 3.864327
## 4    NA  93.2    NA    NA 5.672228 4.850694 4.476869
## 5    NA  62.4    NA    NA 4.365290 4.713670 4.705820
## 6    NA  84.3    NA    NA 3.697726 3.884610 4.384152
##      e2003    e2004    e2005    e2006    e2007    e2008
## 1 4.454100 4.757211 3.734836 3.366183 3.211438 3.495036
## 2 5.610725 8.227844 7.034880 5.588461 5.445144 4.346749
## 3 4.260178 4.091610 4.216728 4.163924 4.568384 4.646109
## 4 4.645306 5.213588 5.353556 5.808850 6.259154 6.121604
## 5 4.885341 4.304562 4.100981 4.226696 4.801925 4.280639
## 6 3.651081 3.365547 2.949490 2.960601 3.013074 2.762090
##      e2009    e2010    e2011    e2012    e2013     e2014
## 1 3.578677 2.736684 2.840603 2.692890 2.990929  2.798719
## 2 4.689046 5.264181 3.777260 6.711859 8.269840 10.178299
## 3 5.311070 5.764874 5.575126 5.322589 5.727331  5.652458
## 4 6.223329 6.146566 5.978840 6.019660 5.074942  5.043462
## 5 4.412473 5.466372 4.468978 4.539596 4.075065  4.033651
## 6 2.936868 3.067742 3.789550 3.503983 3.461137  4.780977
##       e2015    e2016
## 1  2.950431 2.877825
## 2 10.117628 9.927321
## 3  5.884248 6.121374
## 4  5.262711 4.403621
## 5  3.975932 3.974016
## 6  5.827122 5.478273</code></pre>
<p><strong>Code book for Dataframe Fert_prenatal</strong> See Problem 2.3.4 in Section 2.3 homework</p>
<ol start="7" style="list-style-type: decimal">
<li>Maintaining your balance may get harder as you grow older. A study was conducted to see how steady the elderly is on their feet. They had the subjects stand on a force platform and have them react to a noise. The force platform then measured how much they swayed forward and backward, and the data is in table #7.3.14 (Maintaining Balance while Concentrating, 2019). Do the data show that the elderly sway more than the mean forward sway of younger people, which is 18.125 mm? Test at the 5% level. Follow the filtering methods in other homework problems to create a data frame for only Elderly.</li>
</ol>
<p><strong>Table #7.3.14: Sway (in mm) of Elderly Subjects</strong></p>
<div class="sourceCode" id="cb352"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb352-1"><a href="one-sample-inference.html#cb352-1"></a>Sway &lt;-<span class="st"> </span><span class="kw">read.csv</span>(</span>
<span id="cb352-2"><a href="one-sample-inference.html#cb352-2"></a>  <span class="st">&quot;https://krkozak.github.io/MAT160/sway.csv&quot;</span>)</span>
<span id="cb352-3"><a href="one-sample-inference.html#cb352-3"></a><span class="kw">head</span>(Sway)</span></code></pre></div>
<pre><code>##       age fbsway sidesway
## 1 Elderly     19       14
## 2 Elderly     30       41
## 3 Elderly     20       18
## 4 Elderly     19       11
## 5 Elderly     29       16
## 6 Elderly     25       24</code></pre>
<p><strong>Code book for data frame Sway</strong></p>
<p><strong>Description</strong>
How difficult is it to maintain your balance while concentrating? It is more difficult when you are older? Nine elderly (6 men and 3 women) and eight young men were subjects in an experiment. Each subject stood barefoot on a â€œforce platformâ€ and was asked to maintain a stable upright position and to react as quickly as possible to an unpredictable noise by pressing a hand held button. The noise came randomly and the subject concentrated on reacting as quickly as possible. The platform automatically measured how much each subject swayed in millimeters in both the forward/backward and the side-to-side directions.</p>
<p>This data frame contains the following columns:</p>
<p>Age: Elderly or Young</p>
<p>FBSway: Sway in forward/backward direction</p>
<p>SideSwayy: Sway in side to side direction</p>
<p><strong>Source</strong>
Maintaining Balance while Concentrating. (n.d.). Retrieved July 19, 2019, from <a href="http://www.statsci.org/data/general/balaconc.html" class="uri">http://www.statsci.org/data/general/balaconc.html</a></p>
<p><strong>References</strong>
Teasdale, N., Bard, C., La Rue, J., and Fleury, M. (1993). On the cognitive penetrability of posture control. Experimental Aging Research 19, 1-13.
The data was obtained from the DASL Data and Story Line online database.</p>
<p><strong><br />
</strong></p>
<p>Data Sources:</p>
<p>Australian Human Rights Commission, (1996). <em>Indigenous deaths in
custody 1989 - 1996</em>. Retrieved from website:
<a href="http://www.humanrights.gov.au/publications/indigenous-deaths-custody" class="uri">http://www.humanrights.gov.au/publications/indigenous-deaths-custody</a></p>
<p><em>CDC features - new data on autism spectrum disorders</em>. (2013, November
26). Retrieved from <a href="http://www.cdc.gov/features/countingautism/" class="uri">http://www.cdc.gov/features/countingautism/</a></p>
<p>Center for Disease Control and Prevention, Prevalence of Autism Spectrum
Disorders - Autism and Developmental Disabilities Monitoring Network.
(2008). <em>Autism and developmental disabilities monitoring network-2012</em>.
Retrieved from website:
<a href="http://www.cdc.gov/ncbddd/autism/documents/ADDM-2012-Community-Report.pdf" class="uri">http://www.cdc.gov/ncbddd/autism/documents/ADDM-2012-Community-Report.pdf</a></p>
<p>Federal Trade Commission, (2008). <em>Consumer fraud and identity theft
complaint data: January-December 2007</em>. Retrieved from website:
<a href="http://www.ftc.gov/opa/2008/02/fraud.pdf" class="uri">http://www.ftc.gov/opa/2008/02/fraud.pdf</a></p>
<p>Sanchez, Y. W. (2016, October 20). Poll: Arizona voters still favor legalizing marijuana. Retrieved from <a href="https://www.azcentral.com/story/news/politics/elections/2016/10/20/poll-arizona-marijuana-legalization-proposition-205/92417690/" class="uri">https://www.azcentral.com/story/news/politics/elections/2016/10/20/poll-arizona-marijuana-legalization-proposition-205/92417690/</a></p>
<p><a href="http://apps.who.int/gho/athena/data/download.xsl?format=xml&amp;target=GHO/WHOSIS_000001&amp;profile=excel&amp;filter=COUNTRY" class="uri">http://apps.who.int/gho/athena/data/download.xsl?format=xml&amp;target=GHO/WHOSIS_000001&amp;profile=excel&amp;filter=COUNTRY</a>:<em>;SEX:</em>;REGION:EUR</p>
<p>CO2 emissions (metric tons per capita). (n.d.). Retrieved July 18, 2019, from <a href="https://data.worldbank.org/indicator/EN.ATM.CO2E.PC" class="uri">https://data.worldbank.org/indicator/EN.ATM.CO2E.PC</a></p>
<p>(n.d.). Retrieved July 18, 2019, from <a href="https://www.idvbook.com/teaching-aid/data-sets/the-breakfast-cereal-data-set/" class="uri">https://www.idvbook.com/teaching-aid/data-sets/the-breakfast-cereal-data-set/</a>
The Best Kidsâ€™ Cereal. (n.d.). Retrieved July 18, 2019, from <a href="https://www.ranker.com/list/best-kids-cereal/ranker-food" class="uri">https://www.ranker.com/list/best-kids-cereal/ranker-food</a></p>
<p>Lange TL, Royals HE, Connor LL (1993) Influence of water chemistry on mercury concentration in largemouth bass from Florida lakes. Trans Am Fish Soc 122:74-84.
Michael K. Saiki, Darell G. Slotton, Thomas W. May, Shaun M. Ayers, and Charles N. Alpers (2000) Summary of Total Mercury Concentrations in Fillets of Selected Sport Fishes Collected during 2000â€“2003 from Lake Natoma, Sacramento County, California (Raw data is included in appendix), U.S. Geological Survey Data Series 103, 1-21.
NISER 081107 ID Data. (n.d.). Retrieved July 18, 2019, from <a href="http://wiki.stat.ucla.edu/socr/index.php/NISER_081107_ID_Data" class="uri">http://wiki.stat.ucla.edu/socr/index.php/NISER_081107_ID_Data</a></p>
<p>SOCR Data 2008 World CountriesRankings. (n.d.). Retrieved July 19, 2019, from <a href="http://wiki.stat.ucla.edu/socr/index.php/SOCR_Data_2008_World_CountriesRankings#SOCR_Data_-_Ranking_of_the_top_100_Countries_based_on_Political.2C_Economic.2C_Health.2C_and_Quality-of-Life_Factors" class="uri">http://wiki.stat.ucla.edu/socr/index.php/SOCR_Data_2008_World_CountriesRankings#SOCR_Data_-_Ranking_of_the_top_100_Countries_based_on_Political.2C_Economic.2C_Health.2C_and_Quality-of-Life_Factors</a></p>
<p>Maintaining Balance while Concentrating. (n.d.). Retrieved July 19, 2019, from <a href="http://www.statsci.org/data/general/balaconc.html" class="uri">http://www.statsci.org/data/general/balaconc.html</a></p>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="continuous-probability-distributions.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="estimation.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["Statistics_using_technology.pdf", "Statistics_using_technology.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
